---
title: "Tree Canopy Cover Density"
subtitle: |
  [NO_TCCD_001] - Tree Canopy Cover Density indicator in forests  \
  [NO_TCCD_100 to NO_TCCD_104] - Tree Canopy Cover Density in urban areas 
format: 
  html:
    embed-resources: true
    code-fold: true
    toc: true
    toc-title: Contents
    toc-depth: 3
    smooth-scroll: true
execute: 
  cache: false
author:
  - name: Sylvie Clappe # Enter name
    email: sylvie.clappe@nina.no  # Enter email
    affiliations:
      - id: myID
        name: Norwegian Institute for Nature Research # Enter affiliations
  - name: Bálint Czúcz            #  Enter subsequent authors like this, or remove if not relevant
    email: balint.czucz@nina.no
    affiliations:
      - ref: myID               # To reuse affiliations referecen the id like this
date: July 22, 2025# Enter date 
callout-icon: false
lightbox: true
css: ../../../style.css
code-links:
      - text: Add a review
        icon: github
        href: https://github.com/NINAnor/ecRxiv
bibliography: references.bib
---

<!--# This is a template for how to document the indicator analyses. Make sure also to not change the order, or modify, the headers, unless you really need to. This is because it easier to read if all the indicators are presented using the same layout. If there is one header where you don't have anything to write, just leave the header as is, and don't write anything below it. If you are providing code, be careful to annotate and comment on every step in the analysis. Before starting it is recommended to fill in as much as you can in the metadata file. This file will populate the initial table in your output.-->

<!--# Load all you dependencies here -->

```{r setup}
#| include: false
library(knitr)
library(tidyverse)
library(kableExtra)
library(terra)
library(sf)
library(dplyr)
library(readxl)
library(httr2)
library(glue)
library(tictoc)
library(duckdb)
library(duckdbfs)
library(duckspatial)
library(mirai)
library(purrr)
library(stringr)
library(exactextractr)
library(carrier)
library(hdar)
library(DT)
library(numform)

knitr::opts_chunk$set(echo = TRUE)
```

```{r source}
#| echo: false
source(here::here("_common.R"))
```

```{r}
#| echo: false
meta <- readxl::read_xlsx("../metadata.xlsx")
st <- meta |>
  filter(Variable == "status") |>
  pull(Value)
version <- meta |>
  filter(Variable == "Version") |>
  pull(Value)
auth <- meta |>
  filter(Variable == "authors") |>
  pull(Value)
year <- meta |>
  filter(Variable == "yearAdded") |>
  pull(Value)
id <- meta |>
  filter(Variable == "indicatorID") |>
  pull(Value)
name <- meta |>
  filter(Variable == "indicatorName") |>
  pull(Value)
url <- meta |>
  filter(Variable == "url") |>
  pull(Value)

meta <- meta |>
  mutate(Variable = case_match(Variable,
    "indicatorID" ~ "Indicator ID" ,
    "indicatorName" ~ "Indicator Name",
    "country" ~ "Country",
    "continent" ~ "Continent",
    "ECT" ~ "Ecosystem Condition Typology Class",
    "yearAdded" ~ "Year added",
    "yearLastUpdate" ~ "Last update",
    .default = Variable
   )
  ) |>
  filter(Variable != "authors")

```

<!--# The following parts are autogenerated. Do not edit. -->

```{r}
#| echo: false
#| results: asis
status(st)
```

::: {layout-ncol="2"}



> **Recomended citation**: `r paste(auth, " ", year, ". ", name, " (ID: ", id, ") ", "v. ", version, ". ecRxiv: https://view.nina.no/ecRxiv/", sep="")`

> **Version**: `r version`

:::

```{=html}
<details>
<summary>Show metadata</summary>
```

```{r tbl-meta}
#| tbl-cap: 'Indicator metadata'
#| echo: false
#| warning: false

meta |>
  select(Variable, Value) |>
  kbl(col.names = NULL) 

```

```{=html}
</details>
```

::: {.callout-tip collapse="true"}

## Logg

<!--# Update this logg with short messages for each update -->
- 01 Jan. 1901 - Original PR
:::


<hr />

<!--# Document you work below.  -->

## 1. Summary
<!--# With a maximum of 300 words, describe the indicator in general terms as you would to a non-expert. Think of this as a kind of commmon language summary. It is a good idea to include a bullet point list of the spesific steps in the workflow. Include a mention of the following aspects:
What does the metric represent?
Why is this relevant for describing ecosystem condition in this ecosystem?
What are the main anthropogenig impact factors?
What kind of data is used? 
Shortly, how is the data customized (modified, estimated, integarted) to fit its purpuse as an indicator?
What is the current status of  the metric (can it be used or is it still in development)?
How should the metric be used and interpretted, and how should it not be used/interpretted? -->

Tree canopy cover, or briefly *tree cover*, is the area of the earth that lies underneath the canopy/foliage of high (typically >5 m) woody vegetation when viewed vertically from above. This is typically expressed as the proportion/share of area of the land covered by tree crowns within a broader area of interest (**i.e.,** as the *density* of tree canopies/tree cover). Accordingly, *tree canopy cover density* (TCCD), or *tree cover density* in short, is typically measured from above by using some airborne or space-borne remote sensing technique. 

In principle, TCCD can be quantified for all terrestrial ecosystem types (ETs). From an EU perspective there are, however, two major ETs for which TCCD is considered particularly relevant: 

* The "*tree cover density*" of *forests* (ET04 in the EU ecosystem typology; @et-typo-eurostat) is one of the eight *mandatory* condition variables prescribed by the EU Regulation on Environmental Economic Accounting ([EU Reg. 2011/691](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:02011R0691-20250624)), 

* The average *tree canopy cover*	of *urban ecosystems* is listed as a voluntary condition variable in Eurostat's condition accounting guidelines (@cond-gn-eurostat) for the ecosystem type *settlements and other artificial areas* (ET01 in the EU ecosystem typology)

For both ecosystem types, the calculation of TCCD for a specific reference period and ecosystem accounting area (EAA) will consist of two 2 major steps :

1. Identify the '*target area*' for which the indicator should be calculated (cf. @Czucz2025a),

2. Calculate the mean TCCD within this area (for the selected accounting period).

Nevertheless, there are often several ways of defining the *target area*, and this is particularly true for urban ecosystems. Accordingly, in this document, we will present four different variants of the urban indicator, based on different definitions of the *target area* (see section 1.2). Besides offering a flexible approach for performing the "right" calculation for every reporting context, these variants are also aligned across other *urban* ecosystem condition variables (URGR, URAQ), thus making it easier to establish consistency across the different variables and their policy use. 

### 1.1 Interpretation
An indicator value of 1 signifies that the ecosystem type is fully covered by tree canopy cover. For forest ecosystems, TCCD values decreasing towards zero usually reflect negative ecological change, specifically this can include high fragmentation of the afforested landscape. Note however that a value of 1 can be misleading for two reasons: (i) some forests naturally present open areas that are key components for species and genetic diversity. In those cases the TCCD value will be lower than 1 without negatively affecting the condition of a forest. And (ii) clear-cut forest areas may present a TCCD value of 1 just because young stands regenerate, although overall the condition of these areas are poor as still recovering from uman interventions. 

In the case of urban ecosystems, TCCD values decreasing towards zero may reflect a negative ecological impact as some ecosystem services such as local climate regulation or air filtration will not be provided anymore, causing negative impacts on human health and well-being. 

@BALINT: I know you're going to rewrite everything, I am still really unknowledgeable when it comes to condition. Apologies.

### 1.2 Overview of the different indicator versions

For forests we only calculate one version of this indicator: 

* **TCCD_001**:  Average Tree Cover Density in the forest areas of Norway. Here the *target area* is defined as the total area of ET04 (*Forest and woodlands*) in the Norwegian national ecosystem type map (Grunnkart), which complies with both Eurostat's guidance (@cond-gn-eurostat2025) and the SEEA EA principles. 

An alternative version could potentially also be calculated directly from NIBIO's National Forest Inventory data, but unfortunately *tree cover* as a variable was not assessed consistently in all forest inventory sites: some forest types were left out, which can lead to a biased estimator (see @Czucz2025a).   

For urban ecosystems we present four variants:

* **TCCD_104**: The *target area* is the total area of the ecosystem type ET01 (*Settlements and other artificial areas*) in Norway. This is the option which is most aligned with the principles of SEEA EA (UN et al. 2024), where an ecosystem's condition indicators are expected to be representative of their "parent" ecosystem type (see also @Czucz2025a). 

* **TCCD_101**: The *target area* is the area of the ecosystem type ET01 (*Settlements and other artificial areas*) within the municipalities considered as *"cities"* according to Eurostat's degree of urbanisation (DEGURBA) classification (`DEGURBA = 1`). 

* **TCCD_102**: The *target area* is the area of the ecosystem type ET01 (*Settlements and other artificial areas*) within the municipalities considered as "towns and suburbs" according to Eurostat's DEGURBA classification (`DEGURBA = 2`).

* **TCCD_103**: The *target area* is the area of the ecosystem type ET01 (*Settlements and other artificial areas*) within the municipalities considered as "rural areas" according to Eurostat DEGURBA classification (`DEGURBA = 3`). TCCD_101-TCCD_103 are complementary to each other, they present an overview of the tree cover across all three main types of municipalities in Norway. As the three DEGURBA categories comprise all Norwegian municipalities, the area-weighted mean (for ET01) of these three indicators will be equal to TCCD_104 for any reporting period.  

* **TCCD_100**: The *target area* is the *entire area* of the municipalities considered as "cities" according to Eurostat DEGURBA classification (`DEGURBA = 1`). As the total area of Norwegian municipalities is typically dominated by natural ecosystems (forests, wetlands, mountains, etc.), this version of the indicator will overestimate TCCD in urban ecosystems within municipalities. @BALINT: THE SENTENCE WAS NOT FINISHED, IS THIS WHAT YOU HAD IN MIND?

This last option (TCCD_100) obviously contradicts key principles of ecosystem accounting (the target area covers vast areas of forests, wetlands, grasslands, heathlands, lakes, etc. in addition to a typically small settlement area), so this option should probably not be used for reporting, we just present to maintain consistency with the other urban ecosystem condition indicators (URGR, URAQ) presented in this study. The most SEEA-EA-consistent variant is TCCD_104, which also seems to be aligned with the relatively brief description available for the voluntary variable ("average across all Settlements and other artificial areas"). The calculation of TCCD_101 to TCCD_103 for diverse ecosystem accounting areas (EAAs) might also be useful for the additional analytical insight offered by distinguishing the different types of settlements according to their degree of urbanisation.   



## 2. About the underlying data
<!--# Describe the data you have used in more detail, it's origin, biases, availabilit ect.-->

We use the following two main datasets for our calculations: 

* **Copernicus HRL TCD**: We used the *Tree Cover Density* product of the Copernicus Land Monitoring Service to calculate mean tree canopy cover density over different ecosystem types. 

* **Grunnkart**: Norway's official *ecosystem type map* designed to support ecosystem accounting (@strand2024; @gk2). This map aims at implementing Eurostat's EU ecosystem typology (@et-typo-eurostat) for Norway. Here we use this map for delineating the area of ecosystem type ET01 (*Settlements and other artificial areas*) and ET04 (*Forest and woodlands*).

In addition we use several further administrative datasets to delineate the individual municipalities (i.e., Local Administrative Units, LAU), as well as to determine their "degree of urbanisation" (DEGURBA), and to assign them to regions (counties and "fylke").


### 2.1 Spatial and temporal resolution and extent
<!--# Describe the temporal and spatial resolution and extent of the data used -->

*Copernicus HRL TCD* is available for the whole Europe, including mainland Norway (excluding Svalbard) as a raster file with a high (10 m) resolution. 

All other spatial data files, including the *Grunnkart* and the *Local Administrative Units* (LAU) are vector data (polygons). Unlike traditional land cover maps (e.g., Corine Land Cover), the Grunnkart does not have a single, universal Minimum Mapping Unit (MMU). Instead, the spatial resolution of the Grunnkart is directly inherited from the underlying source datasets used in its creation. This is because the new map is a synthesis and reclassification of existing data rather than a new, independent mapping effort. As the majority of spatial information available in public datasets focusses on human settlements and infrastructure, urban ecosystems are relatively finely represented in the Grunnkart, especially compared to less anthropologically modified ecosystem types. This makes the contours of ET01 overly-detailed, often delineating individual buildings or roads passing through a forest as "urban ecosystems". This also makes the dataset somewhat unfit for its purpose (Rendon et al. 2025) and cumbersome to process. The delineation of ET04 is of comparable detail and quality as forests is the main ecosystem type in Norway. @BALINT: I had to add a line on forest as per Erik's comment but I let you amend.


### 2.2 Original units
<!--# What are the original units for the most relevant  variables in the data-->

The pixel values of Copernicus HRL TCD express the estimated share of tree cover in percentages (i.e., the % of the pixel covered by tree canopies). As each pixel covers ~100 m^2^, this actually corresponds to the estimated tree cover in m^2^. 


### 2.3 Additional comments about the dataset

The actual boundaries of the municipalities were patched together from two sources: Eurostat Local Adminstrative Units (2023) and Kartverkert national municipalities boundries (2024) (see more details in Section 9). The DEGURBA dataset were only used to classify the Norwegian municipalities into three categories (1: "cities", 2: "towns and suburbs", 3: "rural areas") based on their degree of urbanisation. 


#### 2.3.1 Instructions for citing, using and accessing data
<!--# Is the data openly available? If not, how can one access it? What are the key references to the datasets? -->

||Publicly accessible| Data and metadata available Available at|
|----|--|--------|
| **Copernicus Tree Cover Density**  | Yes | Data and description downloadable from the Copernicus [website](https://land.copernicus.eu/en/products/high-resolution-layer-forests-and-tree-cover?tab=overview) and through the Copernicus [WEkEO API](https://wekeo.copernicus.eu/) | 
**Grunnkart**  | No, only upon request to NIBIO | We used test version 0.2, description available in @gk2 and @strand2024 |
| **EU data about the municipalities**  | Yes | Data and description available from Eurostat: [LAU](https://ec.europa.eu/eurostat/web/gisco/geodata/statistical-units/local-administrative-units) and [DEGURBA](https://ec.europa.eu/eurostat/web/nuts/local-administrative-units) |
| **Norwegian data about the municipalities**  | Yes | Data available from Kartverkert: [boundaries](https://kartkatalog.geonorge.no/metadata/administrative-enheter-kommuner/041f1e6e-bdbc-4091-b48f-8a5990f3cc5b) and [identifiers](https://www.kartverket.no/til-lands/fakta-om-norge/norske-fylke-og-kommunar) |

Detailed codes and instructions to download the data are described in Section 9.

## 3. Indicator properties

### 3.1 Ecosystem Condition Typology Class (ECT)
<!--# Describe the rationale for assigning the indicator to the ECT class. See https://oneecosystem.pensoft.net/article/58218/
This doesnt need to be very long. Maybe just a single sentence. -->

Tree Canopy Cover Density can be considered under ECT class B2 (structural state characteristics) as it describes the physical structure of the parent ecosystem (ET04 forests and ET01 urban ecosystems, respectively).


### 3.2 Ecosystem condition characteristic
<!--# Describe the ecosystem condition characteristic represented in the indicator. See 10.3897/oneeco.6.e58218 for information on what these characteristics might be.
For example, and indicator called 'Trenching in mires' could be made to represent an ecosystem characteristic 'Intact hydrology'. The term 'characteristic' is used similar to the term 'criteria' in Multiple Criteria Decition Making. -->

Trees are key structural components of almost all terrestrial ETs. The variable Tree Canopy Cover Density is a simple yet powerful metric describing the abundance of trees, thus structurally characterising the ETs. 

In principle, as trees can act as microhabitats and they also moderate microclimate, an increased TCCD should indicate an increased support for species and genetic diversity (a positive directionality, sensu @Czucz2021). Depending on the type and subtype of the parent ecosystem this relationship is, however, not always true. Some forest subtypes have a naturally open structure, in such forest types an additional increase in TCCD cannot be seen as an improvement of condition. Similarly, in clear-cut areas sapling stands emerge as the forest regenerates. These stands can be quite dense and offer a high Tree Canopy Cover Density even though the overall condition of the forest is poor as still regenerating from human intervention.

@BLINT: we miss a paragraph about TCCD in ET01


### 3.3 Other standards
<!--# Optional: Add text about other spesific standards, e.g. national standards, and how the indicator relates to these -->

In this documentation, we present different variations of the Tree Canopy Cover Density indicator. For forest ecosystems TCCD_001 aligns well both with SEEA EA principles and the requirements for national reporting under EU Regulation 2024/3024 (@eu-2024-3024). For urban ecosystems we recommend the use of TCCD_104 for all reporting purposes, while TCCD_101--103 can provide additional insights by distinguishing the TCCD of rural regions, urbanised regions, and major cities from each other.


### 3.4 Collinearities with other indicators
<!--# Describe known collinearities with other metrices (indicators or variables) that could become problematic if they were also included in the same Ecosystem Condition Assessment as the indicator described here. -->

The TCCD of urban ecosystems will definitely be highly correlated with the abundance of *urban green areas* (URGR), which is one of the mandatory EU condition variables for ET01. As trees provide the air filtration service, which allows to decrease the concentration of pollutants in that air (e.g., particulate matter 2.5) there might also be a correlation with the other mandatory urban indicator, the concentration of *PM25* in urban ecosystems (URAQ).

In more general, the abundance of trees in terrestrial ecosystems is connected to (and possibly more or less correlated with) several further characteristics of these ETs, e.g.:

* other complementary structural characteristics (e.g. the abundance of "gaps" or the share of open areas is expected  to be closely (and inversely) correlated to TCCD)

* near surface microclimate (wind, moisture, temperature), and in particular the availability of light

* habitat availability for several species groups (connected to trees / forests)

* landscape connectivity for several species groups (connected to trees / forests)

* the successional age of communities, the frequency of major disturbance events

### 3.5 Impact factors
<!--# Describe the main natural and anthropogenic factors that affects the metric -->

There are a number of natural and anthropogenic processes that affect the number and size of trees in terrestrial ecosystems. In forests the most important such process is probably human management (forestry activities), the type and intensity of which is decisive for the closedness of tree canopies. Other relevant factors include a number of environmental variables (which often also determine the (sub)type of the forest) as well as disturbance regimes (e.g. fires). 

TCCD in urban ecosystems is also overwhelmingly determined by anthropogenic processes, including conscious urban planning.


## 4. Reference condition and levels

### 4.1 Reference condition
<!--# Define the reference condition (or refer to where it is defined). Note the destinction between reference condition and reference levels 10.3897/oneeco.5.e58216 --> 

Following SEEA EA (@seea-ea), the most suitable *reference condition* for forests is their natural condition, where the structure and composition of the forest is dominated by natural processes, including dynamic equilibria with natural disturbance regimes (SEEA EA 5.70-71). This actually implies slightly different reference conditions for the different forest types. 

For urban ecosystems SEEA EA suggests the identification of an "anthropogenically derived" reference condition (SEEA EA 5.72, a.k.a. "best attainable condition, Vallecillo et al. 2022), which is also an option for highly modified forest types, without any natural counterparts. As this type of reference condition cannot be "sampled" (there is no clear reference set of "cities" in an "optimal/ideal/natural condition"), the best way to operationalise this type of reference condition is to determine optimal reference levels (X~100~) for each variable independently (Czucz2025b), which is also discussed below. 


### 4.2 Reference levels
<!--# If relevant (i.e. if you have normalised a variable), describe the reference levels used to normalise the variable. 
Use the terminology where X~0~ referes to the referece level (the variable value) denoting the worst possible condition; X~100~denotes the optimum or best possible condition; and X~*n*~, where in is between 0 and 100, denotes any other anchoring points linking the variable scale to the indicator scale (e.g. the threshold value between good and bad condition X~60^). 
Why was the current option chosen and how were the reference levels quantified? If the reference values are calculated as part of the analyses further down, please repeat the main information here -->

In this exercise we have not determined *reference levels* and have not applied a proper rescaling for any of the TCCD variables. Nevertheless, we have identified several considerations related to the future selection of these reference levels. 

* **X~100~**: For forests the optimal reference level (X~100~) probably needs to be different for each relevant forest subtype, reflecting the canopy structure of the natural state of the given forest type (e.g. boreal rainforest vs a steep ravine forest). For forest types with a naturally closed canopy $X~100~ = 1$ (100% tree cover) can probably also be a suitable reference level. For urban ecosystems and highly anthropogenic forest types the X~100~ can probably be anchored best using linear extrapolation after the good/bad threshold (X~60~) and the pessimal scale endpoint have already been set (cf. Czucz2025b; Paracchini et al. in prep).

* **X~0~**: The natural zero (0% tree cover) is probably a suitable pessimal reference level (null value) for all TCCD variables, both in forests and in urban ecosystems.

* **X~60~**: The threshold value separating "good" from "not good" condition is probably the most challenging reference level for TCCD. For anthropogenic ecosystem types (e.g. urban ecosystems) this value can probably be best set through a careful analysis of relevant environmental (e.g. planning) norms or targets, reflecting diverse societal perceptions about what can be seen as "good enough" in diverse contexts. For natural forests where both X~100~ and X~0~ are known, X~60~might also be identified using linear interpolation.



#### 4.2.1 Spatial resolution and validity
<!--# Describe the spatial resolution of the reference levels. E.g. is it defined as a fixed value for all areas, or does it vary. Also, at what spatial scale are the reference levels valid? For example, if the reference levels have a regional resolution (varies between regions), it might mean that it is only valid and correct to use for normalising local variable values that are first aggregated to regional scale. However, sometimes the reference levels are insensitive to this and can be used to scale variables at the local (e.g. plot) scale. -->

X~0~ (the null value of TCCD) can be seen as a universal reference level, which is valid for any ET, including any forest subtype. For all other RLs (X~60~, X~100~) the value of the RL will probably need to depend on the ecosystem subtype, and/or possibly also on bioclimatic zone (i.e. "homogeneous ecosystem areas" sensu Vallecillo et al. 2022). 

As in the case of forests each pixel of the map can belong to a different forest type, TCCD should ideally be rescaled at the local scale (pixel by pixel), before any aggregation would happen. Accordingly, a proper rescaling of TCCD into proper "condition indicators" (sensu SEEA EA) will ideally demand a detailed map of the spatial distribution of the different forest subtypes in Norway. The identification of the relevant spatial datasets, ecosystem subtypes, and reference levels needs to be aligned with each other, and this will be a key task for making this ecosystem condition variable really meaningful for policy. In the case of this variable, where the same coverage value may mean a good condition in one forest type, while a very bad condition in another one, aggregating unscaled pixel values across broader areas may lead to confusing and contradictory results. @BALINT: look at Erik's comment for this section, I agree with him but I need your opinion too.


## 5. Uncertainties
<!--# Describe the main uncertainties or sources of error in the indicator or the underlying data. -->

There are several sources of uncertainties affecting the values of this indicator and its subsequent use:

- <u>data uncertainties in Copernicus TCD</u>: The main input data source is itself the output of a complicated machine learning algorithm. While on a pan-European scale the accuracy (including both producer and user accuracy) of the HRL TCD product exceeds 90%, in Norway this accuracy seems to be significantly lower (@Dostalova2021). This can largely be attributed to the complex and uneven topography of the country, which is known to create challenges for satellite-based classification algorithms, leading to lower performance.  

- <u>spatial, temporal and semantic uncertainties of the grunnkart</u>: the current Grunnkart combines many different static data sources with various temporal reference dates, which does not seem to present an easily reproducible and updatable data source. This possibly introduces some "noise" into the delineation of both forests and, in particular, urban ecosystems. As Grunnkart is currently a static dataset, we used for the entire study period the only available timeline (which itself relies on temporally heterogeneous sources in an undocumented way). 


## 6. References
<!--# You can add references manually or use a citation manager and add intext citations as with crossreferencing and hyperlinks. See https://quarto.org/docs/authoring/footnotes-and-citations.html -->

::: {#refs}
:::

<!-- Aune-Lundberg, L., Steinnes, M., Lund, M.O., Arneberg, E. & Munsterhjelm, N. 2025. Testversjon 2 – Nasjonalt grunnkart for bruk i arealregnskap. NIBIO Rapport 11/50/2025. (in Norwegian) -->

<!-- Czúcz, B., Keith, H., Maes, J., Driver, A., Jackson, B., Nicholson, E., Kiss, M., & Obst, C. (2021). Selection criteria for ecosystem condition indicators. Ecological Indicators, 133, 108376. https://doi.org/10.1016/j.ecolind.2021.108376 -->

<!-- Czúcz, B., Framstad, E., Clappe, S. & Nowell, M. 2025a. Exploring the use of Eurostat’s mandatory and voluntary indicators in Norway. NINA Report 2604. Norwegian Institute for Nature Research. -->

<!-- Czúcz, B., Lappalainen, M., Jernberg, S., Korpinen, S. 2025b. Report on definition of reference conditions that describe good ecosystem condition. SELINA Deliverable 3.3. https://project-selina.eu/  -->

<!-- Dostálová, A., Lang, M., Ivanovs, J., Waser, L. T., & Wagner, W. (2021). European Wide Forest Classification Based on Sentinel-1 Data. Remote Sensing, 13(3), 337. https://doi.org/10.3390/rs13030337 -->

<!-- Eurostat 2023. Ecosystem condition accounts – Guidance Note, Fourth Draft. Eurostat Unit E2, Task Force on Ecosystem Accounting, 05 October 2023. Doc. ENV/EA/TF/2023_3/4v2. -->

<!-- Eurostat 2024. EU Ecosystem typology. Technical Note. Version: September 2024. Eurostat. Supplementary document to Doc. ENV/EA/TF/2024_3/2a. -->

<!-- Eurostat 2025. Ecosystem Condition Accounts – Guidance Note, Sixth Draft. Eurostat Unit E2, Task Force on Ecosystem Accounting, 26-27 February 2025. Doc. ENV/EA/TF/2025_1/2. -->

<!-- Strand, G.-H., Steinnes, M., Arneberg, E., Lund, M.O., Munsterhjelm, N., Aune-Lundberg, L. & Rørholt, A. 2024. Grunnkart for bruk i arealregnskap. NIBIO Rapport 10/28/2024. (in Norwegian) -->

<!-- UN et al. 2024. System of Environmental Economic Accounting – Ecosystem Accounting. United Nations, Department of Economic and Social Affairs, Statistics Division. Statistical Papers, Series F No. 124. -->


## 7. Datasets
<!--# Describe the unique datasets seperately under seperate headers (Dataset A, Dataset B, etc.-->

All the datasets used to compile the different versions of the TCCD indicators have been described in the previous sections, links to them are also provided for more information.

We used the following six datasets: 

* **D-1**: *Copernicus HRL TCD* (copernicus.eu): a series of raster datasets used to calculate mean PM2.5 concentration over different spatial scales. 
* **D-2**: *Grunnkart* (NIBIO): a high-resolution vector dataset used to delineate urban areas (ET01: settlements and other artificial areas)
* **D-3** *LAU data* (Local Administrative Units, Eurostat GISCO): a vector dataset was used as the primary data source to delineate the  municipalities 
* **D-4** *DEGURBA*  (Degree of urbanisation) A tabular dataset assigning one of three DEGURBA classes (1: "cities"; 2: "towns and suburbs"; 3: "rural areas") to each municipality. These classes were used to breakdown the results for URAQ_001-003.
* **D-5**: Norwegian *administrative boundaries for municipalities* (Kartverkert) were applied to update the *LAU data* to reflect recent boundary changes (Ålesund municipality divided into two smaller municipalities)
* **D-6**: Norwegian *administrative identifiers for municipalities and fylke* was used to correct the municipalities' ID numbers and to add fylke (county) IDs too. 

## 8. Spatial units
<!--# Describe the spatial units that you rely on in your analyses. Highlight the spatial units (the resolution) that the indicator values should be interpreted at. Potential spatial delineation data should eb introduced under 7.1. Datasets. We recommend using the SEEA EA terminology of Basic Spatial Units (BSU), Ecosystem Asses (EA) and Ecosystem Accounting Area (EAA). -->

The indicator values of the TCCD variable can be interpreted at any spatial scale, even for the pixels (10x10 m) of the original TCD raster maps (basic spatial unit, BSU). The smallest policy-relevant spatial units for all variables characterising ET01 are probably the contiguous forest patches and settlement areas (ecosystem assets, EA). Nevertheless, coarser ecosystem accounting areas (EAA), like the *fylke*s or the *entire country* can also be highly relevant as reporting areas.  


## 9. Analyses
<!--# Use this header for documenting the analyses. Put code in seperate code chunks, and annotate the code in between using normal text (i.e. between the chunks, and try to avoid too many hashed out comments inside the code chunks). Add subheaders as needed. 
Code folding is activated, meaning the code will be hidden by default in the html (one can click to expand it).
Caching is also activated (from the top YAML), meaning that rendering to html will be quicker the second time you do it. This will create a folder inside you project folder (called INDICATORID_cache). Sometimes caching created problems because some operations are not rerun when they should be rerun. Try deleting the cash folder and try again. -->

### Paths to data sources
Before starting any of the analyses, we store the path in which the data will be found. If readers wish to download the data and run this code, they can just change the paths below to their local paths for the rest of the code to function.
```{r}
#| eval: true
#| code-summary: "Paths to the data"

# DEGURBA from Eurostat
path_degurba <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_DEGURBA_Eurostat/EU-27-LAU-2024-NUTS-2024.xlsx"

# LAUs shapefile from Eurostat
path_lau <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_Eurostat/LAU_RG_01M_2023_3035.shp"
path_lau_folder <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_Eurostat/"
path_lau_2024 <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_Eurostat/LAU_EUROSTAT_2024.shp"

# Municipalities from Kartverkert
path_kom <- "/data/R/GeoSpatialData/AdministrativeUnits/Norway_AdministrativeUnits/Original/Norway_Municipalities/Administrative enheter kommuner FGDB-format/Basisdata_0000_Norge_25833_Kommuner_FGDB/Basisdata_0000_Norge_25833_Kommuner_FGDB.gdb"

# Municipalities number 2023 and 2024
path_kom_nb <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/NO_Fylke/kommune_fylke_region_NO_2024.xlsx"

# Grunnkart
path_grunnkart <- "/data/R/GeoSpatialData/LandUse/Norway_Arealregnskap/Original/GrunnkartArealregnskap FGDB-format/"

# Path to functions
path_fn <- paste0(getwd(), "/indicators/NO_TCCD_001_104/R/functions")

# Path to write results
res_path <- "/data/P-Prosjekter2/412413_2023_no_egd/Results/TCCD/"

```

### Update municipal administrative boundaries from Eurostat
To ensure breakdown of the results at municipal level, we use the Eurostat Local Administrative Units shapefile from 2023 updated to 2024. The main reason behind this choice is to keep being comparable with other indicator for which this shapefile had to be used to define urban areas such as URGR, URAQ and TCCD for urban ecosystems. Another more pragmatic reason is that this shapefile is limited to the terrestrial area, while the national data source for municipal administrative boundaries include the marine territory for all coastal municipalities. As our condition indicators are limited to the terrestrial ecosystems (forest and urban ecosystems), we preferred the use of the Eurostat municipal boundaries, also called Local Administrative Units. However, this file needed to be updated manually to 2024 as the last available version was from 2023. This update was necessary as municipalities numbers in Norway underwent significant changes in 2024. Also Ålesund municipalities was divided in two. These changes are presented in the code below but the final shapefile can also be downloaded from NINA' internal repository following the path presented above `path_lau_2024`.
```{r}
#| eval: false
#| code-summary: "Update Eurostat LAUs to 2024"

# Read shapefile and select Norway
lau_no <- st_read(path_lau) %>%
           filter(CNTR_CODE == "NO")

# Read the shapefile from Kartverkert
kom_2024 <- st_read(path_kom, layer = "kommune")

# Select Haram and Ålesund municipalities
har_al_lau <- lau_no %>% 
                filter(LAU_ID == 1507)

har_al_kom <- kom_2024 %>%
                filter(kommunenummer == 1508 | kommunenummer == 1580) %>%
                st_transform(., st_crs(har_al_lau))

# Intersection between Eurostat LAU shapefile and Kartverkert 
# municipality shapefile for Haram and Ålesund municipalities 
kom_nb <- read_excel(path_kom_nb) %>%
            as.data.frame()
kom_nb$kommune_nr_2023[which(kom_nb$kommune_nr_2023 == "301")] <- "0301"

haram_2024 <- st_intersection(har_al_lau, har_al_kom[2,]) %>%
                select(c(colnames(lau_no), kommunenavn)) %>%
                select(!c(LAU_NAME)) %>%
                rename(LAU_NAME = kommunenavn) %>%
                left_join(., kom_nb, by = join_by("LAU_ID" == "kommune_nr_2023")) %>%
                select(LAU_NAME, fylke_nr, kommune_nr_2024, region_name, geometry)
haram_2024$kommune_nr_2024 <- 1580

alesund_2024 <- st_intersection(har_al_lau, har_al_kom[1,]) %>%
                select(colnames(lau_no)) %>%
                left_join(., kom_nb, by = join_by("LAU_ID" == "kommune_nr_2023")) %>%
                select(LAU_NAME, fylke_nr, kommune_nr_2024, region_name, geometry)

# Final LAUs shapefile
lau_no_2024 <- lau_no %>%
                filter(!LAU_ID == 1507) %>%
                left_join(., kom_nb, by = join_by("LAU_ID" == "kommune_nr_2023")) %>%
                select(LAU_NAME, fylke_nr, kommune_nr_2024, region_name, geometry) %>%
                rbind(., haram_2024, alesund_2024) %>%
                st_as_sf()
                
                
```

To compile the different versions of the TCCD indicators for urban ecosystems, we need to append to this shapefile the variable `DEGURBA`, which represent the degree of urbanisation of the municipality. This variable is produced at European level by Eurostat and is freely available. In the code below we join the `DEGURBA` variable to the municipality shapefile. We finish by exporting the shapefile for further analyses in the next sections.
```{r}
#| eval: false
#| code-summary: "Add the DEGURBA variable to the LAU dataset"

# Read excel file with Degurba variable and select Norway
degurba_lau_no <- read_excel(path_degurba, sheet = "NO")

degurba_lau_no$`LAU CODE` <- as.numeric(degurba_lau_no$`LAU CODE`)
degurba_lau_no$`LAU CODE`[which(degurba_lau_no$`LAU CODE` == 0301)] <- 301

# Join lau_no_2024 with DEGURBA
lau_dgurb <- inner_join(lau_no_2024,
                        degurba_lau_no,
                        by = join_by("kommune_nr_2024" == "LAU CODE")) %>%
              select(LAU_NAME, DEGURBA, fylke_nr, kommune_nr_2024, region_name, geometry) %>%
              st_as_sf()

# Export the LAUs updated shapefiles for 2024
# this is necessary for working with duckdb in the next section
st_write(lau_dgurb, paste0(path_lau_folder, "LAU_EUROSTAT_2024.shp"), append = FALSE)

# Clean the R environment
rm(list = setdiff(ls(), 
                  c("path_degurba",
                    "path_kom",
                    "path_kom_nb",
                    "path_lau",
                    "path_lau_folder",
                    "path_lau_2024",
                    "path_grunnkart",
                    "res_path",
                    "lau_dgurb")))

```

### Load and prepare the tree cover density data
We prepared the Tree Canopy Cover Density rasters, they are available on the internal NINA repository indicated above. For transparency we provide the code below to download and prepare the data. Tree canopy cover density layers have been downloaded from Copernicus for the years 2018 to 2021. This can be done using an API query through the WEkEO website (https://help.wekeo.eu/en/articles/6416936-how-to-download-wekeo-data#h_4d7de19c7c) and the `hdar` package. Note that the request through API requires the username and password from the WEkEO website. The API query uses a bounding box but it is quite large, resulting in heavy rasters of 6GB each. That is why a subsequent step of cleaning has been done to mask the cells that were not in Norway, hence decreasing the size of the rasters. These processed rasters are the ones we made available on the internal NINA repository.

```{r}
#| eval: false
#| code-summary: "Load and save Copernicus Tree Cover Density data"

## Download data
# Set credentials and save them in ~/.hdarc for future use
username <- "your_username"
password <-"your_password"
client <- Client$new(username, password, save_credentials = TRUE)

# Initialise Client
client <- Client$new()

# Review and accept Terms & Condition before downloading the data
client$show_terms()
client$terms_and_conditions(term_id = 'all')

# Create API queries
# Note: use the WEkEO Data viewer that will create an automatic API
# Note: Use "SetAOI" to set your bounding box
yrs <- seq(2018, 2021, 1)

api_list <- map(seq_along(yrs), function(i){
  paste0('{
  "dataset_id": "EO:EEA:DAT:HRL:TCF",
  "product_type": "Tree Cover Density",
  "resolution": "10m",', '\n', '"year": "', as.character(yrs[i]),
 '",', '\n', '"bbox": [
    3.896921397870557,
    57.74146916326935,
    31.304658996871815,
    71.29317180330607
  ],
  "itemsPerPage": 200,
  "startIndex": 0
}'
  )
  }
) %>% 
  unlist()


# Search and download the datasets
matches <- map(seq_along(api_list), ~ client$search(api_list[.x]))

output_directory <- "/data/scratch/tmp_sylvie/TCD_Copernicus/2020"

map(seq_along(matches), function(i){
  matches[[i]]$download(output_directory)
})

## Clean data
# Source the functions that will be needed: process_raster_fn() and files_list_fn
source(paste0(path_fn,"/NO_TCCD_functions.R"))

# Path the the raster data
path_tcd_raw_list <- map(seq_along(yrs),  
                         ~paste0("/data/scratch/tmp_sylvie/TCD_Copernicus/",
                                 as.character(yrs[.x]),
                                 "/"))

files_to_read <- map(path_tcd_raw_list, ~files_list_fn(.x))

# Create Norway country boundary based on Eurostat's LAUs
no_eurostat <- st_read(path_lau_2024) %>%
                mutate(union = rep("Norway", nrow(.))) %>%
                group_by(union) %>%
                summarise()

# Create list of folder to write the final raster on NINA's internal repository
path_write_list <- map(seq_along(yrs),  
                         ~paste0("/data/P-Prosjekter2/412413_2023_no_egd/git_data/TCD/",
                                 as.character(yrs[.x]),
                                 "/"))

# Run the processing function
all_combinations <- expand.grid(seq_yrs = seq_along(files_to_read)[1], seq_files = seq_along(files_to_read[[1]][[1]]))

daemons(10)
map2(all_combinations$seq_yrs, all_combinations$seq_files,
             in_parallel(~ process_raster_fn(path_read = files_to_read[[.x]][[1]][.y],
                                norway_mask = no_eurostat,
                                path_write = path_write_list[[.x]],
                                files_names = files_to_read[[.x]][[2]][.y]),
                         process_raster_fn = process_raster_fn,
                         files_to_read = files_to_read,
                         no_eurostat= no_eurostat,
                         path_write_list = path_write_list
             )
)

daemons(0)

# Clean R environment
rm(list = setdiff(ls(), 
                  c("path_degurba",
                    "path_kom",
                    "path_kom_nb",
                    "path_lau",
                    "path_lau_folder",
                    "path_lau_2024",
                    "path_grunnkart",
                    "res_path",
                    "lau_dgurb",
                    "path_write_list")))


```

These files will be used to create virtual rasters during the analyses. We do not create these rasters now as we will paralellise the analyses. When parallelising, the transfer of the pointers stored in the virtual rasters do not transfer well between the different workers. That is why they will be created within each worker later on rather than creating one for all workers that would be stored on NINA's internal repository.

<!-- Now that we have the cleaned the rasters for the Tree Cover Density. We can create a virtual raster for each year that will be used in the subsequent analyses. -->
<!-- ```{r} -->
<!-- #| eval: false -->
<!-- #| code-summary: "Create virtual raster of Copernicus Tree Cover Density data" -->

<!-- ## Create a virtual raster for each year -->
<!-- # Create a list of the SMOD raster tiles -->
<!-- filename_list_vrt <- map(seq_along(path_write_list), -->
<!--                           ~list.files(path = path_write_list[[.x]], pattern = '\\.tif$', -->
<!--                                  all.files = TRUE, full.names = TRUE)) -->

<!-- filename_vrt_cln <- map(seq_along(filename_list_vrt), -->
<!--                         ~normalizePath(filename_list_vrt[[.x]])) -->

<!-- # Create the virtual raster -->
<!-- tcd_vrt <- map(seq_along(filename_vrt_cln), -->
<!--                ~vrt(filename_vrt_cln[[.x]])) -->
<!-- ``` -->


#### Load and prepare the forest data
To allow for a breakdown at municipal level, we start by intersecting Eurostat Local Administrative Units with the class "Forest and woodlands" from the Grunnkart. Results at municipal level will be aggregated at national level in the Result section later on. 

Spatial intersections between municipalities and Grunnkart are computing intensive. To reduce the time, we use the `duckdb` package. Note that tiles 33, 34, 50, 55 and 56 of the Grunnkart, had to be cleaned separately as functions in `duckdb` could not make the geometry valid but functions in `sf` package could.
```{r}
#| eval: false
#| code-summary: "Forests per LAUs"
# Code by Jennifer Hansen & Sylvie Clappe

## Path to data
# Grunnkart
gdb_files <- list.files(path_grunnkart, pattern = "_gdb\\.gdb$", 
                        full.names = TRUE)

## Clean Grunnkart tile 33, 34, and 55
# Clean
gdb_issue_tiles <- gdb_files[c(7, 8, 13, 14, 15)]

daemons(3)
grunnkart_cln <- map(seq_along(gdb_issue_tiles), 
                     in_parallel(function(i){
                                    # Read library
                                    library(dplyr)
                                    library(sf)
  
                                    # Function
                                    grunnkart_cleaned <- st_read(gdb_issue_tiles[i], 
                                                                 query = "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Forest and woodlands'") %>%
                                                          st_transform(., crs = "EPSG:3035") %>%
                                                          st_buffer(., 0)
                                    return(grunnkart_cleaned)
                                            },
                                gdb_issue_tiles = gdb_issue_tiles)
                      )
daemons(0)

# Check
daemons(3)
grunnkart_check <- map(seq_along(grunnkart_cln), 
                       in_parallel(function(i){
                                    # Read library
                                    library(sf)
  
                                    # Function
                                    check_val <- which(st_is_valid(grunnkart_cln[[i]]) == FALSE) %>% 
                                                  length()
                                    return(check_val)
                                              },
                                    grunnkart_cln = grunnkart_cln)
                        )
daemons(0)



## Database setup
conn <- dbConnect(duckdb())
ddbs_install(conn)
ddbs_load(conn)


## Limit the number of threads (cores) duckdb uses
dbExecute(conn, "PRAGMA threads = 10")


## Register grunnkart_34 in the duckdb database
ddbs_write_vector(conn, grunnkart_cln[[1]], "grunnkart_valid_33")
ddbs_write_vector(conn, grunnkart_cln[[2]], "grunnkart_valid_34")
ddbs_write_vector(conn, grunnkart_cln[[3]], "grunnkart_valid_50")
ddbs_write_vector(conn, grunnkart_cln[[4]], "grunnkart_valid_55")
ddbs_write_vector(conn, grunnkart_cln[[5]], "grunnkart_valid_56")


# Check that the table was registered
ddbs_list_tables(conn)


## Write SQL queries to re-project the grunnkart and make its geometry valid
query_valid <-glue("
CREATE TABLE grunnkart_valid AS
SELECT
  okosystemtype_1,
  ST_Transform(ST_MakeValid(geo), 'EPSG:25832', 'EPSG:3035', true) AS geom
  FROM grunnkart
  WHERE okosystemtype_1 = 'Forest and woodlands'
")

query_valid_18_55 <- glue("
CREATE TABLE grunnkart_valid AS
SELECT
  okosystemtype_1,
  ST_Transform(ST_MakeValid(geo), 'EPSG:25833', 'EPSG:3035', true) AS geom
  FROM grunnkart
  WHERE okosystemtype_1 = 'Forest and woodlands'
")

query_valid_34 <- glue("
CREATE TABLE grunnkart_valid AS
SELECT
  okosystemtype_1,
  geo AS geom
  FROM grunnkart_valid_34
  WHERE okosystemtype_1 = 'Forest and woodlands'
")

query_valid_33 <- glue("
CREATE TABLE grunnkart_valid AS
SELECT
  okosystemtype_1,
  geo AS geom
  FROM grunnkart_valid_33
  WHERE okosystemtype_1 = 'Forest and woodlands'
")

query_valid_50 <- glue("
CREATE TABLE grunnkart_valid AS
SELECT
  okosystemtype_1,
  geo AS geom
  FROM grunnkart_valid_50
  WHERE okosystemtype_1 = 'Forest and woodlands'
")

query_valid_55 <- glue("
CREATE TABLE grunnkart_valid AS
SELECT
  okosystemtype_1,
  geo AS geom
  FROM grunnkart_valid_55
  WHERE okosystemtype_1 = 'Forest and woodlands'
")

query_valid_56 <- glue("
CREATE TABLE grunnkart_valid AS
SELECT
  okosystemtype_1,
  geo AS geom
  FROM grunnkart_valid_56
  WHERE okosystemtype_1 = 'Forest and woodlands'
")

query_intersect <- glue("
CREATE TABLE grunnkart_intersection AS
SELECT g.*, l.*
FROM grunnkart_valid g
JOIN lau_fylke l
ON ST_Intersects(g.geom, l.geom)")

query_drop <- glue("
ALTER TABLE grunnkart_intersection
DROP COLUMN geom_1")


## Intersection - source the function needed: do_intersection_forest
source(paste0(path_fn,"/NO_TCCD_functions.R"))

# Create the input to the intersection function
numextract <- function(string){str_extract(string, "[-+]?[0-9]*\\.?[0-9]+")
}  
fylke_nb_gdb_vec <- map(seq_along(gdb_files), ~ numextract(gdb_files[.x])) %>%
                      unlist() %>%
                      as.numeric()

# Perform the intersection
forest_lau_inter <- map(seq_along(fylke_nb_gdb_vec), 
                      ~ do_intersection_forest(conn, fylke_nb_gdb_vec[.x], gdb_files, fylke_nb_gdb_vec, path_lau_2024))

# Close the connection to duckdb database (remove in-memory dB)
dbDisconnect(conn)

# Clean the R environment
rm(list = setdiff(ls(), 
                  c("path_degurba",
                    "path_kom",
                    "path_kom_nb",
                    "path_lau",
                    "path_lau_folder",
                    "path_lau_2024",
                    "path_grunnkart",
                    "res_path",
                    "lau_dgurb",
                    "forest_lau_inter")))
```

#### Load and prepare the urban area data
To allow for a breakdown at municipal level, we intersect Eurostat Local Administrative Units with the class "Settlements and other artificial areas" from the Grunnkart. Results at municipal level will be aggregated at national level in the Result section later on.

As previously, we use the `duckdb` package to reduce computing time. Note that tile 34 of the Grunnkart, had to be cleaned separately as functions in `duckdb` could not make the geometry valid but functions in `sf` package could.
```{r}
#| eval: false
#| code-summary: "Settlements per LAUs"
# Code by Jennifer Hansen & Sylvie Clappe

## Path to data
# Grunnkart
gdb_files <- list.files(path_grunnkart, pattern = "_gdb\\.gdb$", 
                        full.names = TRUE)

## Clean Grunnkart tile 34
# Clean
grunnkart_34 <- st_read(gdb_files[8], query = "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Settlements and other artificial areas'") %>%
                  st_transform(., crs = "EPSG:3035") %>%
                  st_buffer(., 0)

# Check
which(st_is_valid(grunnkart_34) == FALSE) %>% length()


## Database setup
conn <- dbConnect(duckdb())
ddbs_install(conn)
ddbs_load(conn)


## Limit the number of threads (cores) duckdb uses
dbExecute(conn, "PRAGMA threads = 30")


## Register grunnkart_34 in the duckdb database
ddbs_write_vector(conn, grunnkart_34, "grunnkart_valid_34")



# Check that the table was registered
ddbs_list_tables(conn)


## Write SQL queries to re-project the grunnkart and make its geometry valid
query_valid <-glue("
CREATE TABLE grunnkart_valid AS
SELECT
  okosystemtype_1,
  ST_Transform(ST_MakeValid(geo), 'EPSG:25832', 'EPSG:3035', true) AS geom
  FROM grunnkart
  WHERE okosystemtype_1 = 'Settlements and other artificial areas'
")

query_valid_18_55 <- glue("
CREATE TABLE grunnkart_valid AS
SELECT
  okosystemtype_1,
  ST_Transform(ST_MakeValid(geo), 'EPSG:25833', 'EPSG:3035', true) AS geom
  FROM grunnkart
  WHERE okosystemtype_1 = 'Settlements and other artificial areas'
")

query_valid_34 <- glue("
CREATE TABLE grunnkart_valid AS
SELECT
  okosystemtype_1,
  geo AS geom
  FROM grunnkart_valid_34
  WHERE okosystemtype_1 = 'Settlements and other artificial areas'
")

query_valid_56 <- glue("
CREATE TABLE grunnkart_valid AS
SELECT
  okosystemtype_1,
  ST_Transform(ST_MakeValid(geo), 'EPSG: 25835', 'EPSG:3035', true) AS geom
  FROM grunnkart
  WHERE okosystemtype_1 = 'Settlements and other artificial areas'
")

query_intersect <- glue("
CREATE TABLE grunnkart_intersection AS
SELECT g.*, l.*
FROM grunnkart_valid g
JOIN lau_fylke l
ON ST_Intersects(g.geom, l.geom)")

query_drop <- glue("
ALTER TABLE grunnkart_intersection
DROP COLUMN geom_1")


## Intersection - source the function needed: do_intersection_urban
source(paste0(path_fn,"/NO_TCCD_functions.R"))


# Create the input to the intersection function
numextract <- function(string){str_extract(string, "[-+]?[0-9]*\\.?[0-9]+")
}  
fylke_nb_gdb_vec <- map(seq_along(gdb_files), ~ numextract(gdb_files[.x])) %>%
                      unlist() %>%
                      as.numeric()

# Perform the intersection
soaa_lau_inter <- map(seq_along(fylke_nb_gdb_vec), 
                      ~ do_intersection_urban(conn, fylke_nb_gdb_vec[.x], gdb_files, fylke_nb_gdb_vec, path_lau_2024))


# Close the connection to duckdb database (remove in-memory dB)
dbDisconnect(conn)

# Clean the R environment
rm(list = setdiff(ls(), 
                  c("path_degurba",
                    "path_kom",
                    "path_kom_nb",
                    "path_lau",
                    "path_lau_folder",
                    "path_lau_2024",
                    "path_grunnkart",
                    "res_path",
                    "lau_dgurb",
                    "forest_lau_inter",
                    "soaa_lau_inter")))
```

### Extract tree cover density percentage
Now that we have the forest and the urban areas within each municipalities, we can extract the raster cells of tree cover density corresponding to the forest or urban polygons within each municipality. Note that for this we use the `exact_extract()` function which works only with polygons. This means that we need to first clean the forest and urban layers created previously to only keep the polygons. Due to processing errors in the spatial intersection, TCCD_001 could not be compiled for municipalities Røst and Træna.

```{r}
#| eval: false
#| code-summary: "Extract Tree Cover Density percenatges in forest and urban areas"

## Iteration variables
# List of municipalities numbers 
lau_2024 <- st_read(path_lau_2024)

lau_nb <- unique(lau_2024$k__2024) %>%
            as.character()
lau_nb[35] <- "0301"

# List the years of interest
yrs <- seq(2018, 2021, 1)

## Check nb of municipalities
forest_lau_inter_kom <- lapply(forest_lau_inter, function(i) unique(i$k__2024)) %>%
                          unlist() %>%
                          unique() # 355 instead of 357. Two are missing: Røst and Træna.

soaa_lau_inter_kom <- lapply(soaa_lau_inter, function(i) unique(i$k__2024)) %>%
                          unlist() %>%
                          unique() # all are present

## Clean SOAA: keep only polygons
daemons(15)
soaa_lau <-  soaa_lau_inter %>%
              map(., in_parallel(~ sf:::st_collection_extract(.x,
                                                              type = "POLYGON", 
                                                              warn = FALSE))) %>%
              compact() %>%  
              bind_rows()

forest_lau <-  forest_lau_inter %>%
                 map(., in_parallel(~ sf:::st_collection_extract(.x,
                                                                 type = "POLYGON", 
                                                                 warn = FALSE))) %>%
                compact() %>%  
                bind_rows()

daemons(0)
  

## - source the function to extract tcd raster cells corresponding to polygons: extract_rast
source(paste0(path_fn,"/NO_TCCD_functions.R"))


## Extract tcd mean percentage per forest or urban polygons
daemons(5)

soaa_tcd <- map(seq_along(lau_nb), function(municipality_idx){
  
  # Filter municipality
  municipality_code <- lau_nb[municipality_idx]
  soaa_filtered <- soaa_lau %>%
                    filter(k__2024 == as.numeric(municipality_code))
  
  # Parallelise the extraction of raster cells for each year
  
  soaa_tcd_cells <- map(seq_along(yrs), 
                        in_parallel(function(j){
                          extract_rast(bd_shp = soaa_filtered,
                                       year = yrs[j]
                                       )
                          }, extract_rast = extract_rast,
                          soaa_filtered = soaa_filtered,
                          yrs = yrs))
  return(soaa_tcd_cells)
  }
  )

forest_tcd <- map(seq_along(lau_nb), function(municipality_idx){
  
  # Filter municipality
  municipality_code <- lau_nb[municipality_idx]
  forest_filtered <- forest_lau %>%
                    filter(k__2024 == as.numeric(municipality_code))
  
  # Parallelise the extraction of raster cells for each year
  
  forest_tcd_cells <- map(seq_along(yrs), 
                        in_parallel(function(j){
                          extract_rast(bd_shp = forest_filtered,
                                       year = yrs[j]
                                       )
                          }, extract_rast = extract_rast,
                          forest_filtered = forest_filtered,
                          yrs = yrs))
  return(forest_tcd_cells)
  }
  )

lau_tcd <- map(seq_along(lau_nb), function(municipality_idx){
  
  # Filter municipality
  municipality_code <- lau_nb[municipality_idx]
  lau_filtered <- lau_2024 %>%
                    filter(k__2024 == as.numeric(municipality_code))
  
  # Parallelise the extraction of raster cells for each year
  
  lau_tcd_cells <- map(seq_along(yrs), 
                        in_parallel(function(j){
                          extract_rast(bd_shp = lau_filtered,
                                       year = yrs[j]
                                       )
                          }, extract_rast = extract_rast,
                          lau_filtered = lau_filtered,
                          yrs = yrs))
  return(lau_tcd_cells)
  }
  )

daemons(0)

## Check nb of municipalities again
forest_lau_poly_kom <- forest_lau %>%
                        st_drop_geometry()%>%
                        select(k__2024) %>%
                        unique() #355: still two missing as expected.

soaa_lau_poly_kom <- soaa_lau %>%
                        st_drop_geometry()%>%
                        select(k__2024) %>%
                        unique() #357 as expected

lau_poly_kom <- lau_tcd %>%
                  st_drop_geometry()%>%
                  select(k__2024) %>%
                  unique() #357 as expected


## Clean the R environment
rm(list = setdiff(ls(), 
                  c("path_degurba",
                    "path_kom",
                    "path_kom_nb",
                    "path_lau",
                    "path_lau_folder",
                    "path_lau_2024",
                    "path_grunnkart",
                    "res_path",
                    "lau_dgurb",
                    "tcd_vrt",
                    "forest_lau_inter",
                    "soaa_lau_inter",
                    "soaa_lau",
                    "forest_lau",
                    "soaa_tcd",
                    "forest_tcd",
                    "lau_tcd")))
```

Now that the mean tree cover density has been extracted from the Tree Cover Density rasters for each polygon of each municipality and each year (2018-2021), for both urban and forests areas, we need to compile a summary table that will give the mean tree cover density per municipality.
```{r}
#| eval: false
#| code-summary: "Mean Tree Cover Density in forest and urban areas per municipalities"
## Raw data
soaa_tcd_df <- soaa_tcd %>% 
                compact() %>%
                bind_rows() 

forest_tcd_df <- forest_tcd %>% 
                    compact() %>%
                    bind_rows() 

lau_tcd_df <- lau_tcd %>%
                compact() %>%
                bind_rows() 

## Average Tree Cover Density in the SOAA of the municipality
soaa_tcd_av <- soaa_tcd_df %>%
                rename(kommune_nummer = k__2024) %>%
                group_by(year, fylk_nr, kommune_nummer, DEGURBA) %>%
                summarise(mean_soaa_tcd_perc = mean(mean),
                          sd_soaa_tcd_perc = sd(mean),
                          total_soaa_area_m2 = sum(area_m2))

forest_tcd_av <- forest_tcd_df %>%
                  rename(kommune_nummer = k__2024) %>%
                  group_by(year, fylk_nr, kommune_nummer, DEGURBA) %>%
                  summarise(mean_forest_tcd_perc = mean(mean),
                            sd_forest_tcd_perc = sd(mean),
                            total_forest_area_m2 = sum(area_m2))

## Clean the R environment
rm(list = setdiff(ls(), 
                  c("path_degurba",
                    "path_kom",
                    "path_kom_nb",
                    "path_lau",
                    "path_lau_folder",
                    "path_lau_2024",
                    "path_grunnkart",
                    "res_path",
                    "lau_dgurb",
                    "tcd_vrt",
                    "forest_lau_inter",
                    "soaa_lau_inter",
                    "soaa_lau",
                    "forest_lau",
                    "soaa_tcd",
                    "forest_tcd",
                    "lau_tcd",
                    "soaa_tcd_av",
                    "forest_tcd_av",
                    "lau_tcd_av")))
```

### Summary table to derive TCCD
Now we can build an overall table that we will be able to use to calculate all the versions of the TCCD indicator in the Results section below.

```{r}
#| eval: false
#| code-summary: "Summary table"

## Export tables of results
write.table(soaa_tcd_av, paste0(res_path, "TCCD_summary_table_urban_6Oct2025.csv"), sep = ";", row.names = FALSE)
write.table(soaa_tcd_df, paste0(res_path, "TCCD_raw_data_urban_6OCT2025.csv"), sep = ";", row.names = FALSE)

write.table(forest_tcd_av, paste0(res_path, "TCCD_summary_table_forest_3OCT2025.csv"), sep = ";", row.names = FALSE)
write.table(forest_tcd_df, paste0(res_path, "TCCD_raw_data_forest_3OCT2025.csv"), sep = ";", row.names = FALSE)

write.table(lau_tcd_df, paste0(res_path, "TCCD_raw_data_lau_6OCT2025.csv"), sep = ";", row.names = FALSE)

## Clean R Environment
rm(ls())
```


## 10. Results
<!--# Repeat the final results here. Typically this is a map or table of indicator values.
This is typically where people will harvest data from, so make sure to include all relevant output here, but don't clutter this section with too much output either. -->

From the summary table that we exported previously, we create a summary table with the following indicators:

* **TCCD_001**: Average TCCD in the forest areas of Norway (class Forest and woodlands of the EU Ecosystem Typology)

<!-- * **TCCD_001**: Average Tree Cover Density in the forest areas of municipalities in Norway (class Forest and woodlands of the EU Ecosystem Typology) -->

* **TCCD_100**: Average TCCD in the *whole area of* the municipalities considered as "cities" according to Eurostat classification: degree of urbanisation equal to 1 (`DEGURBA = 1`). Due to methodological limitations, no standard error is associated with this indicator. Further improvements will be implemented with future revisions of the TCCD indicators.

* **TCCD_101**: Average TCCD in the urban areas (class Settlements and other artificial areas of the EU Ecosystem Typology) within the municipalities considered as "cities" according to Eurostat classification: degree of urbanisation equal to 1 (`DEGURBA = 1`)

* **TCCD_102**: Average TCCD in the urban areas (class Settlements and other artificial areas of the EU Ecosystem Typology) within the municipalities considered as "towns and suburbs" according to Eurostat classification: degree of urbanisation equal to 1 (`DEGURBA = 2`)

* **TCCD_103**: Average TCCD in the urban areas (class Settlements and other artificial areas of the EU Ecosystem Typology) within the municipalities considered as "rural" according to Eurostat classification: degree of urbanisation equal to 1 (`DEGURBA = 3`)

* **TCCD_104**: Average TCCD in the urban areas of Norway (class Settlements and other artificial areas of the EU Ecosystem Typology) 

Below, we present two kinds of summary table: one national, and one presenting a breakdown by municipalities.

### National Results
```{r}
#| eval: true
#| code-summary: "National summary table"

## Read exported table
forest_res_raw <- read.table("/data/P-Prosjekter2/412413_2023_no_egd/Results/TCCD/TCCD_raw_data_forest_3OCT2025.csv", sep = ";", head = TRUE)
urban_res_raw <- read.table("/data/P-Prosjekter2/412413_2023_no_egd/Results/TCCD/TCCD_raw_data_urban_6OCT2025.csv", sep = ";", head = TRUE)
lau_res_raw <- read.table("/data/P-Prosjekter2/412413_2023_no_egd/Results/TCCD/TCCD_raw_data_lau_9OCT2025.csv", sep = ";", head = TRUE)

## TCCD_001

tccd_001_nat <- forest_res_raw %>%
                  select(year, LAU_NAM, k__2024, mean, area_m2) %>%
                  group_by(year) %>%
                  summarise(mean_tcd_national = round2(mean(mean), 2),
                            w_mean_tcd_national = round2(weighted.mean(mean, area_m2), 2),
                            count_n = n(),
                            sd_tcd_national = round2(sd(mean), 2),
                            se_tcd_national = round2(sd(mean)/sqrt(count_n), 2)) %>%
                  mutate(ID = "TCCD_001")

## TCCD_100
tccd_100_nat <- lau_res_raw %>%
                  filter(DEGURBA == 1) %>%
                  select(year, LAU_NAM, k__2024, mean, area_m2) %>%
                  group_by(year) %>%
                  summarise(w_mean_tcd_national = round2(weighted.mean(mean, area_m2), 2)) %>%
                  mutate(ID = "TCCD_100")

## TCCD_101
tccd_101_nat <- urban_res_raw %>%
                  filter(DEGURBA == 1) %>%
                  select(year, LAU_NAM, k__2024, mean, area_m2) %>%
                  group_by(year) %>%
                  summarise(mean_tcd_national = round2(mean(mean), 2),
                            w_mean_tcd_national = round2(weighted.mean(mean, area_m2), 2),
                            count_n = n(),
                            sd_tcd_national = round2(sd(mean), 2),
                            se_tcd_national = round2(sd(mean)/sqrt(count_n), 2)) %>%
                  mutate(ID = "TCCD_101")

## TCCD_102
tccd_102_nat <- urban_res_raw %>%
                  filter(DEGURBA == 2) %>%
                  select(year, LAU_NAM, k__2024, mean, area_m2) %>%
                  group_by(year) %>%
                  summarise(mean_tcd_national = round2(mean(mean), 2),
                            w_mean_tcd_national = round2(weighted.mean(mean, area_m2), 2),
                            count_n = n(),
                            sd_tcd_national = round2(sd(mean), 2),
                            se_tcd_national = round2(sd(mean)/sqrt(count_n), 2)) %>%
                  mutate(ID = "TCCD_102")

## TCCD_103
tccd_103_nat <- urban_res_raw %>%
                  filter(DEGURBA == 3) %>%
                  select(year, LAU_NAM, k__2024, mean, area_m2) %>%
                  group_by(year) %>%
                  summarise(mean_tcd_national = round2(mean(mean), 2),
                            w_mean_tcd_national = round2(weighted.mean(mean, area_m2), 2),
                            count_n = n(),
                            sd_tcd_national = round2(sd(mean), 2),
                            se_tcd_national = round2(sd(mean)/sqrt(count_n), 2)) %>%
                  mutate(ID = "TCCD_103")

## TCCD_104
tccd_104_nat <- urban_res_raw %>%
                  select(year, LAU_NAM, k__2024, mean, area_m2) %>%
                  group_by(year) %>%
                  summarise(mean_tcd_national = round2(mean(mean), 2),
                            w_mean_tcd_national = round2(weighted.mean(mean, area_m2), 2),
                            count_n = n(),
                            sd_tcd_national = round2(sd(mean), 2),
                            se_tcd_national = round2(sd(mean)/sqrt(count_n), 2)) %>%
                  mutate(ID = "TCCD_104")

res_national <- bind_rows(tccd_001_nat,
                          tccd_101_nat,
                          tccd_102_nat,
                          tccd_103_nat,
                          tccd_104_nat) %>%
                mutate(Indicator = "Tree Canopy Cover Density",
                       Accounting_area = "Norway") %>%
                select(Indicator, ID, Accounting_area, year, w_mean_tcd_national, se_tcd_national)

colnames(res_national) <- c("Indicator",
                            "ID",
                            "Accounting area",
                            "Accounting period",
                            "Average Tree Canopy Cover Density (%)",
                            "Standard error (%)")

datatable(res_national)
```

### Municipality level
```{r}
#| eval: true
#| message: false
#| code-summary: "Municipal summary table"

## Read exported table
forest_res_raw <- read.table("/data/P-Prosjekter2/412413_2023_no_egd/Results/TCCD/TCCD_raw_data_forest_3OCT2025.csv", sep = ";", head = TRUE)
urban_res_raw <- read.table("/data/P-Prosjekter2/412413_2023_no_egd/Results/TCCD/TCCD_raw_data_urban_6OCT2025.csv", sep = ";", head = TRUE)
lau_res_raw <- read.table("/data/P-Prosjekter2/412413_2023_no_egd/Results/TCCD/TCCD_raw_data_lau_6OCT2025.csv", sep = ";", head = TRUE)

## Compile the different URAQ indicators at national level

# TCCD_001
tccd_001_mun <- forest_res_raw %>%
                  select(year, LAU_NAM, k__2024, mean, area_m2) %>%
                  group_by(year, LAU_NAM, k__2024) %>%
                  summarise(mean_tcd_municip= round2(mean(mean), 2),
                            w_mean_tcd_municip= round2(weighted.mean(mean, area_m2), 2),
                            count_n = n(),
                            sd_tcd_municip = round2(sd(mean), 2),
                            se_tcd_municip = round2(sd(mean)/sqrt(count_n), 2)) %>%
                  mutate(ID = "TCCD_001")

# TCCD_100
tccd_100_mun <- lau_res_raw %>%
                  filter(DEGURBA == 1) %>%
                  select(year, LAU_NAM, k__2024, mean, area_m2) %>%
                  mutate(w_mean_tcd_national = round2(mean, 2),
                         ID = "TCCD_100")


# TCCD_101
tccd_101_mun <- urban_res_raw %>%
                  filter(DEGURBA == 1) %>%
                  select(year, LAU_NAM, k__2024, mean, area_m2) %>%
                  group_by(year, LAU_NAM, k__2024) %>%
                  summarise(mean_tcd_municip= round2(mean(mean), 2),
                            w_mean_tcd_municip= round2(weighted.mean(mean, area_m2), 2),
                            count_n = n(),
                            sd_tcd_municip = round2(sd(mean), 2),
                            se_tcd_municip = round2(sd(mean)/sqrt(count_n), 2)) %>%
                  mutate(ID = "TCCD_101")

tccd_102_mun <- urban_res_raw %>%
                  filter(DEGURBA == 2) %>%
                  select(year, LAU_NAM, k__2024, mean, area_m2) %>%
                  group_by(year, LAU_NAM, k__2024) %>%
                  summarise(mean_tcd_municip= round2(mean(mean), 2),
                            w_mean_tcd_municip= round2(weighted.mean(mean, area_m2), 2),
                            count_n = n(),
                            sd_tcd_municip = round2(sd(mean), 2),
                            se_tcd_municip = round2(sd(mean)/sqrt(count_n), 2)) %>%
                  mutate(ID = "TCCD_102")

tccd_103_mun <- urban_res_raw %>%
                  filter(DEGURBA == 3) %>%
                  select(year, LAU_NAM, k__2024, mean, area_m2) %>%
                  group_by(year, LAU_NAM, k__2024) %>%
                  summarise(mean_tcd_municip= round2(mean(mean), 2),
                            w_mean_tcd_municip= round2(weighted.mean(mean, area_m2), 2),
                            count_n = n(),
                            sd_tcd_municip = round2(sd(mean), 2),
                            se_tcd_municip = round2(sd(mean)/sqrt(count_n), 2)) %>%
                  mutate(ID = "TCCD_103")

res_municip <- bind_rows(tccd_001_mun,
                         tccd_100_mun,
                         tccd_101_mun,
                         tccd_102_mun,
                         tccd_103_mun) %>%
              mutate(Indicator = "Tree Canopy Cover Density") %>%
              select(Indicator, ID, LAU_NAM, k__2024, year, w_mean_tcd_municip, se_tcd_municip) 
              
      
colnames(res_municip) <- c("Indicator",
                           "ID",
                           "Accounting area (municipality name)",
                           "Accounting area (municipality number)",
                           "Accounting period",
                           "Average Tree Canopy Cover Density (%)",
                           "Standard deviation (%)")

datatable(res_municip)
```


## 11. Export file
<!--# Optional: Display the code (don't execute it) or the workflow for exporting the indicator values to file. Ideally the indicator values are exported as a georeferenced shape or raster file with indicators values, reference values and errors. You can also chose to export the raw (un-normalised or unscaled variable) as a seperate product. You should not save large sptaial output data on GitHub. You can use eval=FALSE to avoid code from being executed (example below - delete if not relevant) -->

Finally we present a sample code which can export the results into csv or xlsx files: 

```{r export}
#| eval: false
#| code-summary: "Code to export the result tables above"

#CSV
write.table(res_national, "TCCD_NO_national_2018_2021.csv")
write.table(res_municip, "TCCD_NO_regional_2018_2021.csv")

#Excel
write_xlsx(res_national, "TCCD_NO_national_2018_2021.xlsx")
write_xlsx(res_municip, "TCCD_NO_regional_2018_2021.xlsx")

```

