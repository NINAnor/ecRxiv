---
title: "Urban Green"
subtitle: |
  [NO_URGR_013] - Urban green in Local Administrative Units with Grunnkart, including urban green categories \
  [NO_URGR_022] - Urban green in Urban Clusters of Local Administrative Units with Grunnkart, including urban green categories  \
  [NO_URGR_023] - Urban green in the settlements of the Local Administrative Unites with Grunnkart, including urban green categories  \
  [NO_URGR_025] - Urban green in settlements defined as non-impervious areas from the settlements in Local Administrative Units with Grunnkart  \
  [NO_URGR_030] - Urban green in settlements defined as non-impervious areas from the settlements in Corine Land Cover \
  [NO_URGR_031] - Urban green in settlements defined as non-impervious areas from the settlements in Grunnkart
format: 
  html:
    embed-resources: true
    code-fold: true
    toc: true
    toc-title: Contents
    toc-depth: 3
    smooth-scroll: true
execute:
  cache: true
author:
  - name: Sylvie Clappe              # Enter name
    email: sylvie.clappe@nina.no  # Enter email
    affiliations:
      - id: myID
        name: Norwegian Institute for Nature Research # Enter affiliations
  - name: Bálint Czúcz              
    email: balint.czucz@nina.no
    affiliations:
      - ref: myID               # To reuse affiliations referecen the id like this
date: April 22, 2025 # Enter date 
callout-icon: false
lightbox: true
css: ../../../style.css
code-links:
      - text: Add a review
        icon: github
        href: https://github.com/NINAnor/ecRxiv
        bibliography: references.bib
---

<!--# This is a template for how to document the indicator analyses. Make sure also to not change the order, or modify, the headers, unless you really need to. This is because it easier to read if all the indicators are presented using the same layout. If there is one header where you don't have anything to write, just leave the header as is, and don't write anything below it. If you are providing code, be careful to annotate and comment on every step in the analysis. Before starting it is recommended to fill in as much as you can in the metadata file. This file will populate the initial table in your output.-->

<!--# Load all you dependencies here -->

```{r setup}
#| include: false
library(knitr)
library(tidyverse)
library(kableExtra)
library(terra)
library(sf)
library(exactextractr)
library(dplyr)
library(purrr)
library(readxl)
knitr::opts_chunk$set(echo = TRUE)
```

```{r source}
#| echo: false
source(here::here("_common.R"))
```

```{r}
#| echo: false
meta <- readxl::read_xlsx("../metadata.xlsx")
st <- meta |>
  filter(Variable == "status") |>
  pull(Value)
version <- meta |>
  filter(Variable == "Version") |>
  pull(Value)
auth <- meta |>
  filter(Variable == "authors") |>
  pull(Value)
year <- meta |>
  filter(Variable == "yearAdded") |>
  pull(Value)
id <- meta |>
  filter(Variable == "indicatorID") |>
  pull(Value)
name <- meta |>
  filter(Variable == "indicatorName") |>
  pull(Value)
url <- meta |>
  filter(Variable == "url") |>
  pull(Value)

meta <- meta |>
  mutate(Variable = case_match(Variable,
    "indicatorID" ~ "Indicator ID" ,
    "indicatorName" ~ "Indicator Name",
    "country" ~ "Country",
    "continent" ~ "Continent",
    "ECT" ~ "Ecosystem Condition Typology Class",
    "yearAdded" ~ "Year added",
    "yearLastUpdate" ~ "Last update",
    .default = Variable
   )
  ) |>
  filter(Variable != "authors")

```

<!--# The following parts are autogenerated. Do not edit. -->

```{r}
#| echo: false
#| results: asis
status(st)
```

::: {layout-ncol="2"}



> **Recommended citation**: `r paste(auth, " ", year, ". ", name, " (ID: ", id, ") ", "v. ", version, ". ecRxiv: https://view.nina.no/ecRxiv/", sep="")`

> **Version**: `r version`

:::

```{=html}
<details>
<summary>Show metadata</summary>
```

```{r tbl-meta}
#| tbl-cap: 'Indicator metadata'
#| echo: false
#| warning: false

meta |>
  select(Variable, Value) |>
  kbl(col.names = NULL) 

```

```{=html}
</details>
```

::: {.callout-tip collapse="true"}

## Logg

<!--# Update this logg with short messages for each update -->
- 01 Jan. 1901 - Original PR
:::


<hr />

<!--# Document you work below.  -->

## 1. Summary
***What is the urban green indicator?*** \
Green spaces in cities are commonly called urban green spaces. They serve a lot of different functions such as contributing to people's mental and physical health, providing cool spaces in summer, as well as improving the air quality by filtrating it from certain pollutants such as particulate matters notably produced by our cars. \
The urban green indicator is usually expressed as an average percentage of urban green spaces covering a city such as 10% or 80%. The higher the percentage, the more green spaces are in a city. As green spaces are mainly considered as a good thing to have in cities, this percentage indicates a certain level of quality, or *condition*. 

***How to calculate a percentage of urban green spaces in a city?*** \
There are 3 major steps in calculating this indicator:

1. Calculate the total area of cities and urban related areas.
2. Within this area, calculate the area of urban green spaces.
3. Calculate a percentage by dividing the two previous figures and multiplying the result by 100.

***How to use and interpret this indicator?*** \
There are several ways of defining areas of cities and urban green, and different datasets that can be used. That is why, in this document, we present six variations of the indicator based on three different analytical approaches. We recommend to use URGR_030 and URGR_031 as they rely on the most ecologically correct definition. They however do not follow the official guidance from the European Commission. If users need to report this indicator in an official EU reporting, we recommend to use URGR_013 or URGR_022.

## 2. About the underlying data
Due to the variations around the definition of what an urban area and an urban green areas are, we had to derive six different indicators. Their definition and associated data are described below:

**1. URGR_013** \
<u>Definition</u> \
This indicator is based on the definitions of urban and urban green areas from @cond-gn-eurostat. They can be summarised as follows:

Urban areas are defined as the Local Administrative Units (LAUs) categorised as "Cities" and their adjacent LAUs classified as "Towns and suburbs". Eurostat defines these LAUs based on the variable "DEGURBA" standing for degree of urbanisation. "Cities" correspond to `DEGURBA = 1`, while "Towns and suburbs" correspond to `DEGURBA = 2`.

Urban green areas are defined as any ecosystems that have a green cover in addition to ponds and watercourses. In their guidance (@cond-gn-eurostat) do not list precisely all the ecosystem types from the EU Ecosystem Typology that should be used. We included the following: 1.4 Urban greenspace; 1.5.2 Cemeteries; 2. Cropland; 3. Grassland; 4. Forest and woodlands; 5. Heathland and shrub; 6. Sparsely vegetated ecosystems; 7. Inland wetlands; 8. Rivers and Canals; 9. Lakes and reservoirs; 11. Coastal beaches, dunes and wetlands.

<u>Datasets used</u> \
Three data sources were used (see more details in the following section): \

|| Origin | Used for | Link |
|---------|-----|------|------|
| **Grunnkart**     |  NIBIO   | Extract urban green areas | Available from NIBIO: https://kartkatalog.geonorge.no/metadata/grunnkart-for-bruk-i-arealregnskap-testversjon-1/28c28e3a-d88f-4a34-8c60-5efe6d56a44d. Or available from NINA's internal repository: /data/R/GeoSpatialData/LandUse/Norway_Arealregnskap/Original/GrunnkartArealregnskap FGDB-format. |
| **Administrative boundaries - Local Administrative Units**      |  European Commission    | Delineate Local Adminstrative Units in Norway | Raw data available from Eurostat here: https://ec.europa.eu/eurostat/web/gisco/geodata/statistical-units/local-administrative-units. Or available from NINA's internal repository here: /data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO. Data already prepared for URGR_013 here: /data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO.  | 
| **Administrative boundaries - DEGURBA**      | European Commission    | Used to select the Local Administrative Units classified as "cities" (`DEGURBA = 1`) and the adjacent Local Adminstrative Units classified as "towns and suburbs" (`DEGURBA = 2`) |  Raw file available from Eurostat here: https://ec.europa.eu/eurostat/web/nuts/local-administrative-units. Or from NINA's internal repository here: /data/P-Prosjekter2/412413_2023_no_egd/git_data/Administrative_boundaries_NO |


**2. URGR_022** \
<u>Definition</u> \
This indicator is based on the definitions of urban and urban green areas from @cond-gn-eurostat. They can be summarised as follows:

Urban areas are defined as the "urban domain" of the Local Administrative Units (LAUs) categorised as "Cities" and their adjacent LAUs classified as "Towns and suburbs". Eurostat defines these LAUs based on the variable "DEGURBA" standing for degree of urbanisation. "Cities" correspond to `DEGURBA = 1`, while "Towns and suburbs" correspond to `DEGURBA = 2`. "Urban domains" are defined with the Global Human Settlement Layer SMOD developed through teh Copernicus programme.

Urban green areas are defined as URGR_013.

<u>Datasets used</u> \
Three data sources were used:\

|| Origin | Used for | Link |
|---------|-----|------|------|
| **Grunnkart**     |  NIBIO   | Extract urban green areas | Available from NIBIO: https://kartkatalog.geonorge.no/metadata/grunnkart-for-bruk-i-arealregnskap-testversjon-1/28c28e3a-d88f-4a34-8c60-5efe6d56a44d. Or available from NINA's internal repository: /data/R/GeoSpatialData/LandUse/Norway_Arealregnskap/Original/GrunnkartArealregnskap FGDB-format. |
| **Administrative boundaries - Local Administrative Units**      |  European Commission    | Delineate Local Adminstrative Units in Norway | Raw data available from Eurostat here: https://ec.europa.eu/eurostat/web/gisco/geodata/statistical-units/local-administrative-units. Or available from NINA's internal repository here: /data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO. Data already prepared for URGR_013 here: /data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO.  | 
| **Administrative boundaries - DEGURBA**      | European Commission    | Used to select the Local Administrative Units classified as "cities" (`DEGURBA = 1`) and the adjacent Local Adminstrative Units classified as "rowns and suburbs" (`DEGURBA = 2`) |  Raw file available from Eurostat here: https://ec.europa.eu/eurostat/web/nuts/local-administrative-units. Or from NINA's internal repository here: /data/P-Prosjekter2/412413_2023_no_egd/git_data/Administrative_boundaries_NO |
| **Global Human Settlement Layer - SMOD**     | European Commission - Joint Research Center | Used to delineate urban domains within Local Administrative Units |  Raw data are available here: https://human-settlement.emergency.copernicus.eu/download.php?ds=smod. SMOD data filtered for Norway are available on NINA's internal repository: /data/P-Prosjekter2/412413_2023_no_egd/git_data/SMOD_2018 |



**3. URGR_023** \
<u>Definition</u> \
This indicator is a variation from the definitions of urban and urban green areas from @cond-gn-eurostat. They can be summarised as follows:

Urban areas are defined as the settlements of the Local Administrative Units (LAUs) categorised as "Cities" and their adjacent LAUs classified as "Towns and suburbs". Eurostat defines these LAUs based on the variable "DEGURBA" standing for degree of urbanisation. "Cities" correspond to `DEGURBA = 1`, while "Towns and suburbs" correspond to `DEGURBA = 2`. The settlements correspond to the ecosystem type 1. Settlements and other artificial areas as defined in the EU Ecosystem Typology.

Urban green areas are defined as for URGR_013.

<u>Datasets used</u> \
The datasets used for URGR_023 were the same than for URGR_013. THis time, not ethat the Grunnkart was used both to extract the urban green areas, but also the urban areas themselves.


**4. URGR_025** \
<u>Definition</u> \
This indicator is a variation of URGR_023. It can be summarised as follows:

Urban areas are defined as for URGR_023.

Urban green areas are defined as the non-impervious areas within the settlements of the Local Administrative Units. These "non-impervious" areas are defined using the Imperviousness Copernicus layer.

<u>Datasets used</u> \
Three data sources were used:\

|| Origin | Used for | Link |
|---------|-----|------|------|
| **Corine Land Cover 2018**      |  Copernicus   | Extract urban areas within Local Administrative Units | Available from the EEA: https://land.copernicus.eu/en/products/corine-land-cover?tab=datasets. Or available from NINA's internal repository: /data/R/GeoSpatialData/LandCover/Norway_CORINE_Landcover/Original/CORINE_2018. |
| **Administrative boundaries - Local Administrative Units**      |  European Commission    | Delineate Local Adminstrative Units in Norway | Raw data available from Eurostat here: https://ec.europa.eu/eurostat/web/gisco/geodata/statistical-units/local-administrative-units. Or available from NINA's internal repository here: /data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO. Data already prepared for URGR_013 here: /data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO.  | 
| **Administrative boundaries - DEGURBA**      | European Commission    | Used to select the Local Administrative Units classified as "cities" (`DEGURBA = 1`) and the adjacent Local Adminstrative Units classified as "rowns and suburbs" (`DEGURBA = 2`) |  Raw file available from Eurostat here: https://ec.europa.eu/eurostat/web/nuts/local-administrative-units. Or from NINA's internal repository here: /data/P-Prosjekter2/412413_2023_no_egd/git_data/Administrative_boundaries_NO |
| **Imperviousness**     | Copernicus | Used to calculate areas of non impervious areas (= urban green and blue spaces) | Available from Copernicus here: https://land.copernicus.eu/en/products/high-resolution-layer-imperviousness. Or available from NINA's internal repository here: /data/P-Prosjekter2/412413_2023_no_egd/git_data/IMD_2018_010m_no_03035_v020/DATA/ |


**5. URGR_030** \
<u>Definition</u> \
This indicator uses definitions of urban areas and urban green areas that are different from @cond-gn-eurostat. They can be summarised as follows:

Urban areas are defined as the EU Ecosystem Typology class 1. Settlements and other artificial areas occurring at national scale. This indicator is not restricted to Norwegian Local Administrative Units only.

Urban green areas are defined as in URGR_025.

<u>Datasets used</u> \
Three data sources were used: \

|| Origin | Used for | Link |
|---------|-----|------|------|
| **Grunnkart**      |  NIBIO  | Extract urban areas at national level|Available from NIBIO: https://kartkatalog.geonorge.no/metadata/grunnkart-for-bruk-i-arealregnskap-testversjon-1/28c28e3a-d88f-4a34-8c60-5efe6d56a44d. Or available from NINA's internal repository: /data/R/GeoSpatialData/LandUse/Norway_Arealregnskap/Original/GrunnkartArealregnskap FGDB-format.|
| **Administrative boundaries for Fylke**      |  Kartverkert    | Delineate Fylke to disaggregate the results | Available on Geonorge: https://kartkatalog.geonorge.no/metadata/administrative-enheter-fylker/6093c8a8-fa80-11e6-bc64-92361f002671. Or available on NINA's internal repository: /data/R/GeoSpatialData/AdministrativeUnits/Norway_AdministrativeUnits/Processed/Norge_kystlinje_fylker_2024.shp. Or can also be accessed here: /data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/NO_Regions_Fylke  | 
| **Administrative boundaries for Regions - Regions and Fylke identifiers**    | Kartverkert    | Used to aggregate the Fylke results by regions |  Available from Kartverkert here:https://www.kartverket.no/til-lands/fakta-om-norge/norske-fylke-og-kommunar |
| **Imperviousness**     | Copernicus | Used to calculate areas of non impervious areas (= urban green and blue spaces) | Available from Copernicus here: https://land.copernicus.eu/en/products/high-resolution-layer-imperviousness. Or available from NINA's internal repository here: /data/P-Prosjekter2/412413_2023_no_egd/git_data/IMD_2018_010m_no_03035_v020/DATA/ |



**6. URGR_031** \
<u>Definition</u> \
Same definition than URGR_030, but using Corine Land Cover 2018, instead of the Grunnkart.

<u>Datasets used</u> \
Three data sources were used: \

|| Origin | Used for | Link |
|---------|-----|------|------|
| **Corine Land Cover 2018**      |  Copernicus   | Extract urban areas at national level | Available from the EEA: https://land.copernicus.eu/en/products/corine-land-cover?tab=datasets. Or available from NINA's internal repository: /data/R/GeoSpatialData/LandCover/Norway_CORINE_Landcover/Original/CORINE_2018.|
| **Administrative boundaries for Fylke**      |  Kartverkert    | Delineate Fylke to disaggregate the results | Available on Geonorge: https://kartkatalog.geonorge.no/metadata/administrative-enheter-fylker/6093c8a8-fa80-11e6-bc64-92361f002671. Or available on NINA's internal repository: /data/R/GeoSpatialData/AdministrativeUnits/Norway_AdministrativeUnits/Processed/Norge_kystlinje_fylker_2024.shp. Or can also be accessed here: /data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/NO_Regions_Fylke  | 
| **Administrative boundaries for Regions - Regions and Fylke identifiers**    | Kartverkert    | Used to aggregate the Fylke results by regions |  Available from Kartverkert here:https://www.kartverket.no/til-lands/fakta-om-norge/norske-fylke-og-kommunar |
| **Imperviousness**     | Copernicus | Used to calculate areas of non impervious areas (= urban green and blue spaces) | Available from Copernicus here: https://land.copernicus.eu/en/products/high-resolution-layer-imperviousness. Or available from NINA's internal repository here: /data/P-Prosjekter2/412413_2023_no_egd/git_data/IMD_2018_010m_no_03035_v020/DATA/ |


- **Corine Land Cover 2018** from the EEA. Available from the EEA: https://land.copernicus.eu/en/products/corine-land-cover?tab=datasets. Or available from NINA's internal repository: /data/R/GeoSpatialData/LandCover/Norway_CORINE_Landcover/Original/CORINE_2018.




<!--# Describe the data you have used in more detail, it's origin, biases, availabilit ect.-->

### 2.1 Spatial and temporal resolution and extent
|| Spatial scale | Spatial Resolution | Spatial Accuracy |
|---------|-----|------|------|
| **Grunnkart**     |  National - Norway   | MMU: 2-50m, depending on the ecosystem type mapped    | 1 to 500m depending on the dataset used to create the polygon |
| **Corine Land Cover**    | Europe   | 100m x 100m| Thematic accuracy > or = to 85% |
| **Copernicus Imperviousness**     |    Europe    | 10m x 10m | Thematic accuracy > or = to 90% |
| **Global Human Settlement Layer - SMOD**     |  National - Norway    | 1km x 1km | NA |
| **Administrative boundaries - Local Administrative Units**      |  National - Norway    | NA | NA  | 
| **Administrative boundaries - Fylke**      |  National - Norway    | NA | NA |
| **Administrative boundaries - Regions and Fylke identifiers**      | National - Norway    | NA |  NA | 
| **Administrative boundaries - DEGURBA**      | National - Norway    | NA |  NA |



<!--# Describe the temporal and spatial resolution and extent of the data used -->

### 2.2 Original units
|| Original units |
|---------|-----|
| **Grunnkart**     | this dataset is a composite of multiple geospatial datasets that have been harmonised, cleaned and standardised for ecosystem accounting.  |
| **Corine Land Cover**    | derived from satellite imageries | 
| **Copernicus Imperviousness**     | derived from satellite imageries | 
| **Global Human Settlement Layer - SMOD**     | derived from satellite imageries|
| **Administrative boundaries - Local Administrative Units**      | NA |
| **Administrative boundaries - Fylke**      | NA |  
| **Administrative boundaries - Regions and Fylke identifiers**      | NA |
| **Administrative boundaries - DEGURBA**      | NA |
<!--# What are the original units for the most relevant  variables in the data-->

### 2.3 Additional comments about the dataset
|| Origin | Year | Format |
|---------|-----|------|------|
| **Grunnkart**     | NIBIO   |    NA (released year: 2025) | vector |
| **Corine Land Cover**    | Copernicus  |   2018 |  raster | 
| **Copernicus Imperviousness**     | Copernicus    |     2018 |  raster | 
| **Global Human Settlement Layer - SMOD**     | European Commission - Joint Research Center |     2020 |raster|
| **Administrative boundaries - Local Administrative Units**      | European Commission    |  2023   |  vector |
| **Administrative boundaries - Fylke**      | Kartvetkert    |    2024 |  vector |  
| **Administrative boundaries - Regions and Fylke identifiers**      | Kartverkert    |     2024 |   excel file |
| **Administrative boundaries - DEGURBA**      | European Commission     |     2024 |    excel file |
<!--# Text here -->

#### 2.3.1 Instructions for citing, using and accessing data

|| Publicly accessible | Link |
|---------|-----|------|
| **Grunnkart**     | No, upon request | https://kartkatalog.geonorge.no/metadata/nasjonalt-grunnkart-for-arealanalyse-testversjon-2/28c28e3a-d88f-4a34-8c60-5efe6d56a44d |
| **Corine Land Cover**    | yes | https://land.copernicus.eu/en/products/corine-land-cover/clc2018 |
| **Copernicus Imperviousness**     |yes | https://land.copernicus.eu/en/products/high-resolution-layer-imperviousness/imperviousness-density-2018 |
| **Global Human Settlement Layer - SMOD**     |yes | https://human-settlement.emergency.copernicus.eu/download.php?ds=smod |
| **Administrative boundaries - Local Administrative Units**      |yes | https://ec.europa.eu/eurostat/web/gisco/geodata/statistical-units/local-administrative-units |
| **Administrative boundaries - Fylke**      |yes | https://kartkatalog.geonorge.no/metadata/administrative-enheter-fylker/6093c8a8-fa80-11e6-bc64-92361f002671  |
| **Administrative boundaries - Regions and Fylke identifiers**      |yes | https://www.kartverket.no/til-lands/fakta-om-norge/norske-fylke-og-kommunar | yes |
| **Administrative boundaries - DEGURBA**      | yes |  https://ec.europa.eu/eurostat/web/nuts/local-administrative-units |


<!--# Is the data openly available? If not, how can one access it? What are the key references to the datasets?   -->


## 3. Indicator properties

### 3.1 Ecosystem Condition Typology Class (ECT)
The percentage of urban green spaces in urban ecosystems is part of B2 - Structural State as it describes the physical structure of urban ecosystems.
<!--# 

Describe the rationale for assigning the indicator to the ECT class. See https://oneecosystem.pensoft.net/article/58218/
This doesnt need to be very long. Maybe just a single sentence. 

-->

### 3.2 Ecosystem condition characteristic
The share of urban green spaces in urban ecosystems indicates the level of nature that is present in an urban environment. Urban green spaces provide important ecosystem services that are essential to the wellbeing of the human communities living in urban settlements. The presence of green spaces also ensures habitats for wildlife with urban areas.

<!--# 

Describe the ecosystem condition characteristic represented in the indicator. See 10.3897/oneeco.6.e58218 for information on what these characteristics might be.
For example, and indicator called 'Trenching in mires' could be made to represent an ecosystem characteristic 'Intact hydrology'. The term 'characteristic' is used similar to the term 'criteria' in Multiple Criteria Decition Making.  

-->

### 3.3 Other standards
In this documentation, we present different variations of the urban green indicator. We recommend to use URGR_030 and URGR_031 as they rely on the most ecologically correct definition. They however do not follow the official guidance from the European Commission for national reporting under EU Regulation 2024/3024 (@eu-2024-3024). If users need to report this indicator in an official EU reporting, we recommend to use URGR_013 or URGR_022.

<!--# Optional: Add text about other spesific standards, e.g. national standards, and how the indicator relates to these -->

### 3.4 Collinearities with other indicators
Indicators such as Tree cover density or Share of impervious areas in urban ecosystems will be highly correlated to the share of urban green spaces. 

<!--# Describe known collinearities with other metrices (indicators or variables) that could become problematic if they were also included in the same Ecosystem Condition Assessment as the indicator described here. -->


### 3.5 Impact factors
The share of urban green spaces is impacted by a number of factors. The main anthropogenic factors influencing the extent of green spaces in urban areas are urban planning and land-use policies. More natural factors can also impact green spaces such as climate change and water availability which can limit the growth and development of some species.

BALIN TO COMPLETE/REVIEW?

<!--# Describe the main natural and anthropogenic factors that affecst the metric -->


## 4. Reference condition and levels

### 4.1 Reference condition
Urban areas are, by nature, anthropogenic. It is difficult to establish a reference condition for this indicator.

BALIN TO COMPLETE

<!--# Define the reference condition (or refer to where it is defined). Note the destinction between reference condition and reference levels 10.3897/oneeco.5.e58216  -->

### 4.2 Reference levels
This section is not relevant as the indicator has not been normalised using a reference value.

<!--# 

If relevant (i.e. if you have normalised a variable), describe the reference levels used to normalise the variable. 

Use the terminology where X~0~ referes to the referece level (the variable value) denoting the worst possible condition; X~100~denotes the optimum or best possible condition; and X~*n*~, where in is between 0 and 100, denotes any other anchoring points linking the variable scale to the indicator scale (e.g. the threshold value between good and bad condition X~60^). 

Why was the current option chosen and how were the reference levels quantified? If the reference values are calculated as part of the analyses further down, please repeat the main information here.

 -->


#### 4.2.1 Spatial resolution and validity
This section is not relevant as the indicator has not been normalised using a reference value.

<!--# 

Describe the spatial resolution of the reference levels. E.g. is it defined as a fixed value for all areas, or does it vary. Also, at what spatial scale are the reference levels valid? For example, if the reference levels have a regional resolution (varies between regions), it might mean that it is only valid and correct to use for normalising local variable values that are first aggregated to regional scale. However, sometimes the reference levels are insensitive to this and can be used to scale variables at the local (e.g. plot) scale. 

 -->

## 5. Uncertainties
There are two categories of uncertainties that can be considered with the development of this indicator and its subsequent use (@uncertainty):

- <u>Model uncertainty</u>: the data used to compile the urban green indicator all present a degree of uncertainty including spatial and temporal accuracies, the modelling approaches done to obtain the spatial layers especially the Grunnkart, the Imperviousness and Corine Land Cover datasets. In addition, URGR_030 and URGR_031 rely on the mean percentage of imperviousness per polygon of urban ecosystems, which may introduce some uncertainties.

- <u>Decision uncertainty</u>: the indicators presented in this document have been compiled in accordance with different interpretations of the urban green indicator defined by Eurostat for the EU Regulation 2024/3024 (@eu-2024-3024). There are uncertainties due to the interpretations of the indicator and the methodological choices that resulted to calculate them. For example URGR_030 and URGR_031 rely on the assumption that what is not impervious is urban green or blue spaces. While URGR_13 relies on the assumption that urban areas can be summarised by the extent of Local Administrative Units for which the variable DEGURBA equals 1 and 2. All these interpretations and choices results in variability in the results of the different indicators. Finally, one have to consider the interpretation and applications of the results given in this document by the users. The translation of these indicators into decision-making will inherently present some uncertainties as it relies on the users' own experience, expertise and goals, which will influence the understanding of the indicators.

<!--# Describe the main uncertainties or sources of error in the indicator or the underlying data. -->

## 6. References

European Commission (2025). Ecosystem Condition Accounts - Guidance Note 6^{th} Draft. https://circabc.europa.eu/ui/group/922b4700-1c83-4099-b550-763badab3ec0/library/5074c555-99ea-4931-ace8-9351fa174f8b

European Council and Parliament (2024). Regulation (EU) 2024/3024 of the European Parliament and of the Council of 27 November 2024 amending Regulation (EU) No 691/2011 as regards introducing new environmental economic account modules. https://eur-lex.europa.eu/eli/reg/2024/3024/oj/eng

United Nations, (2024). System of Environmental Economic Accounting - Ecosystem Accounting.

Walther Franziska, Barton David N., Schwaab Jonas, Kato-Huerta Jarumi, Immerzeel Bart, Adamescu Mihai, Andersen Erling, Arámbula Coyote Martha Verónica, Arany Ildikó, Balzan Mario, Bruggeman Adriana, Carvalho-Santos Claudia, Cazacu Constantin, Geneletti Davide, Giuca Relu, Inácio Miguel, Lagabrielle Erwann, Lange Sabine, Clec’h Solen Le, Vanessa Lim Zhi Yi, Mörtberg Ulla, Nedkov Stoyan, Portela Ana Paula, Porucznik Anna, Racoviceanu Tudor, Rendón Paula, Ribeiro Daniela, Seguin Joana, Hribar Mateja Šmid, Stoycheva Vanya, Vejre Henrik, Zoumides Christos, Grêt-Regamey Adrienne, (2025). Uncertainties in ecosystem services assessments and their implications for decision support – A semi-systematic literature review. Ecosystem Services 73, 101714. https://doi.org/10.1016/j.ecoser.2025.101714



<!--# You can add references manually or use a citation manager and add intext citations as with crossreferencing and hyperlinks. See https://quarto.org/docs/authoring/footnotes-and-citations.html -->

## 7. Datasets

All the datasets used to compile the different versions of the URGR indicators have been thoroughly describe din the previous sections, link sto them are also provided for more information.

## 8. Spatial units
We have two spatial units in which the urban green indicator has been compiled: national and municipal. In terms of the SEEA-EA, our Ecosystem Accounting Area is the country of Norway (although Svalbård is not included). The Ecosystem Type of interest is the urban ecosystems. Finally, the minimum spatial units at which the results are broken down are the municipalities.

<!--# 

Describe the spatial units that you rely on in your analyses. Highlight the spatial units (the resolution) that the indicator values should be interpretted at. Potential spatial delineation data should eb introduced under 7.1. Datasets. We recomend using the SEEA EA terminology opf Basic Spatial Units (BSU), Ecosystem Asses (EA) and Ecosystem Accounting Area (EAA). 

-->

## 9. Analyses

### 9.1 URGR_013
#### 9.1.1 Preparation of the data
First we need to create separate data sets for each ecosystem types that are relevant to include in "urban green ecosystems". According to the @cond-gn-eurostat, all ecosystem types in the EU Ecosystem Types Typology with a green cover should be included. This means that, in the EU Ecosystem Typology, we only discard: 10. Marine inlets and transitional waters, 12. Marine Ecosystems, and 1. Settlements and Other Artificial areas except classes 1.4 Urban greenspace and 1.5.2 Cemeteries. Note that the new Grunnkart has several tiles and not all of them have the same projection.
```{r}
#| eval: false
#| code-summary: "Create Ecosystem Types datasets"

# Code co-created by Sylvie Clappe and Jennifer E. Hansen
# path to the Grunnkart data
gdb_folder <- "/data/R/GeoSpatialData/LandUse/Norway_Arealregnskap/Original/GrunnkartArealregnskap FGDB-format"

# List the gdb files
gdb_files <- list.files(gdb_folder, pattern = "_gdb\\.gdb$", 
                        full.names = TRUE)

# Define CRS of the first layer (most common CRS of the gdb files)
gk_crs <- st_read(gdb_files[1], query = "SELECT * FROM arealregnskap LIMIT 500") %>%
            crs()

# Function to read a single filtered file
read_gdb <- function(gdb_path, projection_crs) {
  tryCatch({
    layer <- st_read(dsn = gdb_path, layer = "arealregnskap", query = query_string)
  }, error = function(e) {
    message("Error reading: ", gdb_path, "\n", e)
    return(NULL)  # error handling
  })
  
  if (crs(layer) == projection_crs){
    return(layer)} 
  else{
    layer_proj <- st_transform(layer, crs = projection_crs)
    print(crs(layer_proj))
    return(layer_proj)
  }
}

# Create a list of SQL queries: one per ecosystem type
query_string_list <- list()

query_string_list[[1]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_3 = 'Cemeteries'"
query_string_list[[2]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_2 = 'Urban greenspace'"
query_string_list[[3]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Lakes and reservoirs'"
query_string_list[[4]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Cropland'"
query_string_list[[5]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Grassland'"
query_string_list[[6]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Inland wetlands'"
query_string_list[[7]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Sparsely vegetated ecosystems'"
query_string_list[[8]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Rivers and canals'"
query_string_list[[9]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Coastal beaches, dunes and wetlands'"
query_string_list[[10]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Forest and woodlands'"
query_string_list[[11]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Heathland and shrub'"


names(query_string_list) <- c("Cemeteries",
                              "Urban greenspace",
                              "Lakes and reservoirs",
                              "Cropland",
                              "Grassland",
                              "Inland wetland",
                              "Sparsely vegetated ecosystems",
                              "Rives and canals",
                              "Coastal beaches, sand dunes and wetlands",
                              "Forest and woodlands",
                              "Heathland and shrub")

# Run SQL query and store results in a list
for (i in 1: length(query_string_list)){
query_string <- query_string_list[[i]] 

et_data <- gdb_files %>% 
            map(\(.) read_gdb(., projection_crs = gk_crs))  %>% 
            compact() %>%  
            bind_rows()
}

```


To compile URGR_013, we need the Norwegian Local Administrative Units (LAUs) from Eurostat. According to the @cond-gn-eurostat, only LAUs whcih are cities and the LAUs for towns and suburb adjacent to these cities should be selected. We thus used the DEGURBA variable from Eurostat to select the citites (DEGURBA = 1) and towns and suburbs (DEGURBA = 2) that were adjacent to these cities. Below are two codes: (i) one to create the dataset from scratch, and (ii) one that reads the dataset already created and available from NINA's internal repository.

```{r}
#| eval: false
#| code-summary: "Create LAUs dataset"

# Read excel file with Degurba variable and select Norway
path_lau <- "/data/P-Prosjekter2/412413_2023_no_edg/git_data/Adminstrative_boundaries_NO/LAU_DEGURBA_Eurostat/"
degurba_lau_no <- read_excel(paste0(path_lau, "EU-27-LAU-2024-NUTS-2024.xlsx"), sheet = "NO")

# Select cities towns and suburbs
cities_sub_no <- degurba_lau_no %>%
                  select("LAU NAME NATIONAL", "DEGURBA") %>%
                  filter(DEGURBA == 1 | DEGURBA == 2) %>%
                  as.data.frame()

# Read shapefile and select Norway
path_lau <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_Eurostat/"
lau_eu <- st_read(paste0(path_lau, "LAU_RG_01M_2023_3035.shp"))
lau_no <- lau_eu %>%
           filter(CNTR_CODE == "NO")


# Join cities_sub_no with lau_no
byer_lau <- inner_join(cities_sub_no, 
                       lau_no, 
                       by = join_by("LAU NAME NATIONAL" == "LAU_NAME")) %>%
              st_as_sf()

# Select LAUs with DEGURBA == 1
lau_1 <- byer_lau %>%
          filter(DEGURBA == 1) %>%
          mutate(city_group = c(1, 2, 2, 2, 2, 2, 3, 3, 4))

# Select LAUs with DEGURBA == 2 which are adjacent to lau_1
lau_2 <- byer_lau %>%
          filter(DEGURBA == 2)

lau2_adj_id <- st_touches(lau_1, lau_2) %>%
                unlist() %>%
                unique()

lau_2_adj <- lau_2[lau2_adj_id, ]

# Create a variable to group the four cities and their suburbs
city_group <- vector()
  
for(i in 1:nrow(lau_2_adj)){
  
  if(st_touches(lau_1[1,], lau_2_adj[i,], sparse = FALSE)[,1] == TRUE){
    city_group[i] <- 1
  } 
  else if(TRUE %in% st_touches(lau_1[c(2,3,4,5,6),], lau_2_adj[i,], sparse = FALSE)[,1]){
    city_group[i] <- 2
  }
  else if(TRUE %in% st_touches(lau_1[c(7,8),], lau_2_adj[i,], sparse = FALSE)[,1]){
    city_group[i] <- 3
  }
  else if(st_touches(lau_1[9,], lau_2_adj[i,], sparse = FALSE)[,1] == TRUE){
    city_group[i] <- 4
  } else {city_group[i] <- NA}
}

# Add group variable to LAU adatset
lau_2_adj <- mutate(lau_2_adj, city_group = city_group)

# Final LAUs dataset
lau <- rbind(lau_1, lau_2_adj)

```

```{r}
#| eval: false
#| code-summary: "Upload LAUs from NINA's internal repository"

# Path to the data
path_boundaries<- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_URGR/"

# Load the data
lau <- st_read(paste0(path_boundaries, "LAUs_URGR.shp"))
```


#### 9.1.2 Data Cleaning
To have correct spatial analyses, all spatial data loaded before must have the same CRS. We already ensured that the ecosystem types from the Grunnkart have the same CRS. But the administrative boundaries now need to be projected in the same CRS as the one from the ecosystem type.
```{r}
#| eval: false
#| code-summary: "Check CRS and reproject"

# ETs from Grunnkart (we take one as they have all the same CRS)
cemeteries_crs <- crs(et_list[[1]])

# LAUs
lau_crs <- crs(lau)

# Check they are the same
cemeteries_crs == lau_crs


# Re-project boundaries
lau_32 <- st_transform(lau, cemeteries_crs)
```

The next step is to check for geometrical and topological issues and fix them if there are. Note that we use the `st_make_valid()` function from the `sf` package. This function did not work for Sparsely vegetated ecosystems so we used `st_buffer (x, 0, 0)` instead.
```{r}
#| eval: false
#| code-summary: "Geometry and topology - check and fix"

# Check for empty geometry
for(i in 1:length(et_list)){
  empty_test <- which(st_is_empty(et_list[[i]]) == TRUE)
  print(empty_test)
}

lau_32_empty <- which(st_is_empty(lau_32) == TRUE)

# Check validity
for(i in 1:length(et_list)){
  validity_test <- which(st_is_valid(et_list[[i]]) == FALSE)
  print(length(validity_test))
}

lau_32_invalid <- which(st_is_valid(lau_32) == FALSE)

# Clean geometry of ETs with st_make_valid()
et_clean_list <- list()
for(i in c(seq(1,6,1), seq(8,11,1))){
  et_clean <- st_make_valid(et_list[[i]])
  et_clean_list[[i]] <- et_clean
}

et_clean_list[[7]] <- st_buffer(et_list[[7]], 0) %>%
  filter(!st_is_empty(.)) %>%
  st_make_valid()

names(et_clean_list) <- names(et_list)

#  Check cleaning geometry worked
for(i in 1:length(et_clean_list)){
  geometry_check <- which(st_is_valid(et_clean_list[[i]]) == FALSE)
  print(length(geometry_check))
}

# Check for empty geometry
for(i in 1:length(et_clean_list)){
  empty_test <- which(st_is_empty(et_clean_list[[i]]) == TRUE)
  print(empty_test)
}

```

Now we just need to only extract polygons from the ecosystem type data. Some points and line are present. As we are interested in areas, we decide to remove them as they won't contribute to the area estimates. This is also to have a process that will be more comparable to the process used for URGR_30 and URGR_31 for which only polygons are used due to restrictions in the functionalities of the `exact_extract()` function.
```{r}
#| eval: false
#| code-summary: "Final dataset of ecosystem type"

# Keep only polygon features
et_final <- et_clean_list %>%
              map(\(.) st_collection_extract(.,
                                             type = c("POLYGON"), 
                                             warn = FALSE))

names(et_final) <- names(et_clean_list)
```

The resulting data are quite heavy, it is important to clean the R Environment to free memory space.
```{r}
#| eval: false
#| code-summary: "Clean R Environment"

# Remove non-essential R objects-
rm(list=setdiff(ls(), c("et_clean_list",
                        "lau_32")))

```

#### 9.1.3 Data analyses
First we do an intersection of the ecosystem types with the LAUs. That will result in a layer containing only ecosystem types per LAU only.
```{r}
#| eval: false
#| code-summary: "Intersection ecosystem types with LAUs"
#| 
et_list_lau <- et_final %>%
                  map(\(.) st_intersection(., lau_32))

names(et_list_lau) <- names(et_final)

```

Then, we need to calculate the areas of each ecosystem type within the LAUs and the total area of each LAUs.
```{r}
#| eval: false
#| code-summary: "Total area of ecosystem types per LAUs"
#| 
# Calculate areas of ETs in LAUs
et_lau_area <- et_list_lau %>%
                map(\(.) mutate(., et_area_m2  = st_area(.)))

names(et_lau_area) <- names(et_list_lau)

# Calculate areas of LAUs
lau_total_area <- lau_32 %>%
                    mutate(., lau_area_m2 = unclass(st_area(.))) %>%
                    st_drop_geometry() %>%
                    select(LAU_ID, lau_area_m2)
```

We also group the LAUs into four clusters (referred to as "city group" below): Trondheim, Oslo, Stavanger, and Bergen. And we calculate the total area of each group.
```{r}
#| eval: false
#| code-summary: "Group LAUs into four clusters"

# Caluclate area per "city group"
city_group_names <- c("Trondheim", "Oslo", "Stavanger", "Bergen")
city_group_area <- lau_32 %>%
                      mutate(., grp_area_m2 = unclass(st_area(.))) %>%
                      st_drop_geometry() %>%
                      select(cty_grp, grp_area_m2) %>%
                      group_by(cty_grp) %>%
                      summarise(cty_grp_area = sum(grp_area_m2)) %>%
                      cbind(., city_group_names)
```

Finally, we can calculate summary tables for URGR_013:
```{r}
#| eval: false
#| code-summary: "Create summary tables"

# Summary table detailed per LAUs
urgr_013_tab <- et_lau_area %>%
                  compact() %>%
                  bind_rows() %>%
                  st_drop_geometry() %>%
                  select(LAUNAMN, DEGURBA, LAU_ID, cty_grp,
                         okosystemtype_1, okosystemtype_2,
                         okosystemtype_3, okosystemtype_kode,
                         et_area_m2) %>%
                  group_by(cty_grp, LAU_ID, LAUNAMN, okosystemtype_1, okosystemtype_2, okosystemtype_3, okosystemtype_kode) %>%
                  summarise(total_area_et_m2 = sum (et_area_m2)) %>%
                  left_join(., lau_total_area, by = "LAU_ID")

# Summary table aggregated per "city group"
urgr_013_tab_city_gr <- urgr_013_tab %>%
                          group_by(cty_grp, okosystemtype_1, okosystemtype_2, okosystemtype_3, okosystemtype_kode) %>%
                          select(!lau_area_m2) %>%
                          summarise(total_area_et_m2 = sum(total_area_et_m2)) %>%
                          left_join(., city_group_area, by = "cty_grp")
```

These table have been exported to the internal repository and will be used in the Results section to create an overall summary table comparing all URGR indicators.




### 9.2 URGR_022
#### 9.2.1 Load and prepare the data
As for URGR_013, we start by loading all the ecosystem types of interest to define urban green spaces. According to the @cond-gn-eurostat, all ecosystem types in the EU Ecosystem Types Typology with a green cover should be included. This means that, in the EU Ecosystem Typology, we only discard: 10. Marine inlets and transitional waters, 12. Marine Ecosystems, and 1. Settlements and Other Artificial areas except classes 1.4 Urban greenspace and 1.5.2 Cemeteries. Note that the new Grunnkart has several tiles and not all of them have the same projection.
```{r}
#| eval: false
#| code-summary: "Create Ecosystem Types datasets"

# Code co-created by Sylvie Clappe and Jennifer E. Hansen
# Path to the Grunnkart data
gdb_folder <- "/data/R/GeoSpatialData/LandUse/Norway_Arealregnskap/Original/GrunnkartArealregnskap FGDB-format"

# List the gdb files
gdb_files <- list.files(gdb_folder, pattern = "_gdb\\.gdb$", 
                        full.names = TRUE)

# Define CRS of the first layer (most common CRS of the gdb files)
gk_crs <- st_read(gdb_files[1], query = "SELECT * FROM arealregnskap LIMIT 500") %>%
            crs()

# Function to read a single filtered file
read_gdb <- function(gdb_path, projection_crs) {
  tryCatch({
    layer <- st_read(dsn = gdb_path, layer = "arealregnskap", query = query_string)
  }, error = function(e) {
    message("Error reading: ", gdb_path, "\n", e)
    return(NULL)  # error handling
  })
  
  if (crs(layer) == projection_crs){
    return(layer)} 
  else{
    layer_proj <- st_transform(layer, crs = projection_crs)
    print(crs(layer_proj))
    return(layer_proj)
  }
}

# Create a list of SQL queries: one per ecosystem type
query_string_list <- list()

query_string_list[[1]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_3 = 'Cemeteries'"
query_string_list[[2]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_2 = 'Urban greenspace'"
query_string_list[[3]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Lakes and reservoirs'"
query_string_list[[4]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Cropland'"
query_string_list[[5]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Grassland'"
query_string_list[[6]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Inland wetlands'"
query_string_list[[7]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Sparsely vegetated ecosystems'"
query_string_list[[8]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Rivers and canals'"
query_string_list[[9]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Coastal beaches, dunes and wetlands'"
query_string_list[[10]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Forest and woodlands'"
query_string_list[[11]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Heathland and shrub'"


names(query_string_list) <- c("Cemeteries",
                              "Urban greenspace",
                              "Lakes and reservoirs",
                              "Cropland",
                              "Grassland",
                              "Inland wetland",
                              "Sparsely vegetated ecosystems",
                              "Rives and canals",
                              "Coastal beaches, sand dunes and wetlands",
                              "Forest and woodlands",
                              "Heathland and shrub")

# Run SQL query and store results in a list
for (i in 1: length(query_string_list)){
query_string <- query_string_list[[i]] 

et_data <- gdb_files %>% 
            map(\(.) read_gdb(., projection_crs = gk_crs))  %>% 
            compact() %>%  
            bind_rows()
}

```


To compile URGR_022, we need the Norwegian Local Administrative Units (LAUs) from Eurostat. According to the @cond-gn-eurostat, only LAUs whcih are cities and the LAUs for towns and suburb adjacent to these cities should be selected. We thus used the DEGURBA variable from Eurostat to select the citites (DEGURBA = 1) and towns and suburbs (DEGURBA = 2) that were adjacent to these cities. Below are two codes: (i) one to create the dataset from scratch, and (ii) one that reads the dataset already created and available from NINA's internal repository.

```{r}
#| eval: false
#| code-summary: "Create LAUs dataset"

# Read excel file with Degurba variable and select Norway
path_lau <- "/data/P-Prosjekter2/412413_2023_no_edg/git_data/Adminstrative_boundaries_NO/LAU_DEGURBA_Eurostat/"
degurba_lau_no <- read_excel(paste0(path_lau, "EU-27-LAU-2024-NUTS-2024.xlsx"), sheet = "NO")

# Select cities towns and suburbs
cities_sub_no <- degurba_lau_no %>%
                  select("LAU NAME NATIONAL", "DEGURBA") %>%
                  filter(DEGURBA == 1 | DEGURBA == 2) %>%
                  as.data.frame()

# Read shapefile and select Norway
path_lau <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_Eurostat/"
lau_eu <- st_read(paste0(path_lau, "LAU_RG_01M_2023_3035.shp"))
lau_no <- lau_eu %>%
           filter(CNTR_CODE == "NO")


# Join cities_sub_no with lau_no
byer_lau <- inner_join(cities_sub_no, 
                       lau_no, 
                       by = join_by("LAU NAME NATIONAL" == "LAU_NAME")) %>%
              st_as_sf()

# Select LAUs with DEGURBA == 1
lau_1 <- byer_lau %>%
          filter(DEGURBA == 1) %>%
          mutate(city_group = c(1, 2, 2, 2, 2, 2, 3, 3, 4))

# Select LAUs with DEGURBA == 2 which are adjacent to lau_1
lau_2 <- byer_lau %>%
          filter(DEGURBA == 2)

lau2_adj_id <- st_touches(lau_1, lau_2) %>%
                unlist() %>%
                unique()

lau_2_adj <- lau_2[lau2_adj_id, ]

# Create a variable to group the four cities and their suburbs
city_group <- vector()
  
for(i in 1:nrow(lau_2_adj)){
  
  if(st_touches(lau_1[1,], lau_2_adj[i,], sparse = FALSE)[,1] == TRUE){
    city_group[i] <- 1
  } 
  else if(TRUE %in% st_touches(lau_1[c(2,3,4,5,6),], lau_2_adj[i,], sparse = FALSE)[,1]){
    city_group[i] <- 2
  }
  else if(TRUE %in% st_touches(lau_1[c(7,8),], lau_2_adj[i,], sparse = FALSE)[,1]){
    city_group[i] <- 3
  }
  else if(st_touches(lau_1[9,], lau_2_adj[i,], sparse = FALSE)[,1] == TRUE){
    city_group[i] <- 4
  } else {city_group[i] <- NA}
}

# Add group variable to LAU adatset
lau_2_adj <- mutate(lau_2_adj, city_group = city_group)

# Final LAUs dataset
lau <- rbind(lau_1, lau_2_adj)

```

```{r}
#| eval: false
#| code-summary: "Upload LAUs from NINA's internal repository"

# Path to the data
path_boundaries<- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_URGR/"

# Load the data
lau <- st_read(paste0(path_lau, "LAUs_URGR.shp"))
```

Finally, to define the "urban domains" of the LAUs, we need to load the Global Human Settlement Layer data called SMOD. SMOD is provided as tiles that correspond to Norway. Based on this one can create a virtual raster that can be used in the subsequent analyses. We provided two codes below: (i) code tor create the SMOD virtual raster from scratch, and (ii) read in the virtual raster from NINA's internal repository.
```{r}
#| eval: false
#| code-summary: "Create a SMOD virtual raster for Norway"

# Create a list of the SMOD raster tiles
path_smod <- "/data/P-Prosjekter2/412413_2023_no_edg/git_data/SMOD_2018/"
filename_list_smod <- list.files(path = path_smod, pattern = '.tif$', 
                                 all.files = TRUE, full.names = TRUE)

# Create the virtual raster
smod_18 <- vrt(filename_list_smod,
                     filename = paste0(path_smod, "SMOD_2018.vrt"))
```

```{r}
#| eval: false
#| code-summary: "Upload SMOD data from NINA's internal repository"

# Create a list of the SMOD raster tiles
path_smod <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/SMOD_2018/"

# Load in the data
smod_18 <- rast(paste0(path_smod, "SMOD_2018.vrt"))
```


#### 9.2.2 Data cleaning
Not all of our data have the same CRS, we need to check so we know if we have to re-project in the subsequent analyses.
```{r}
#| eval: false
#| code-summary: "Check CRS"

# ETs from Grunnkart (we take one as they have all the same CRS)
cemeteries_crs <- crs(cemeteries)

# LAUs
lau_crs <- crs(lau)

# SMOD
smod_crs <- crs(smod_18)

# Check they are the same
cemeteries_crs == lau_crs
cemeteries_crs == smod_crs
```

The next step is to create the boundaries of the urban areas we will use for the analyses. For this, we take the SMOD data and mask then with the LAUs to have a raster of urban settlements for the LAUs. Then we need to select only the pixel whose values are strictly superior to 21 to define the "urban domain" within LAUs (see page 51 of the SMOD metadata for more information).

```{r}
#| eval: false
#| code-summary: "Create LAU - urban domains layer"

# Re-project boundaries to the raster crs
lau_wm <- st_transform(lau, smod_crs)

# Mask SMOD with LAUs
smod_lau <- terra:::crop(smod_18, lau_wm, mask = TRUE)

#mapview(smod_lau)

# Aggregate classes 30/23/22/21 to form the "urban domain" (page 51 of SMOD metadata)  
lau_urb_domain <- app(smod_lau, fun=function(x){ x[x < 21] <- NA; return(x)})
names(lau_urb_domain) <- "SMOD_18"
```

To perform the subsequent analyses, we then need to re-project `lau_urb_domain` in the CRS of the Grunnkart.
```{r}
#| eval: false
#| code-summary: "Reproject LAU - urban domains layer"
# Polygonise so it can be re-projected
urban_domains_poly <- as.polygons(lau_urb_domain) %>%
                        st_as_sf()

# Re-project urban domains to the Grunnkart CRS
urban_domains_32 <- st_transform(urban_domains_poly, cemeteries_crs)

# Re-project LAUs
lau_32 <- st_transform(lau, cemeteries_crs)
```

Finally, to be cleaner, we intersect this layer with the LAU layer with `lau_urb_domain` to smooth the outwards edges of the urban domain so they fit the LAUs boundaries. At present `lau_urb_domain` is a polygonised raster, which means that the area is a bit bigger than the area of the LAUs, hence this smoothing step.
```{r}
#| eval: false
#| code-summary: "Smooth outwards boundaries of LAU - urban domains layer"
urb_domn_lau_32 <- st_intersection(urban_domains_32, lau_32)
```

Once we have done that, we can perform the geometrical and topological checks of the data, and fix any issues that might arise.
```{r}
#| eval: false
#| code-summary: "Geometry and topology - check and fix"
# Check for empty geometry
for(i in 1:length(et_list)){
  empty_test <- which(st_is_empty(et_list[[i]]) == TRUE)
  print(empty_test)
}

urb_domn_lau_32_empty <- which(st_is_empty(urb_domn_lau_32) == TRUE)

# Check validity
for(i in 1:length(et_list)){
  validity_test <- which(st_is_valid(et_list[[i]]) == FALSE)
  print(length(validity_test))
}

urb_domn_lau_32_invalid <- which(st_is_valid(urb_domn_lau_32) == FALSE)

# Clean geometry of ETs with st_make_valid()
et_clean_list <- list()
for(i in c(seq(1,6,1), seq(8,11,1))){
  et_clean <- st_make_valid(et_list[[i]])
  et_clean_list[[i]] <- et_clean
}

et_clean_list[[7]] <- st_buffer(et_list[[7]], 0) %>%
                        filter(!st_is_empty(.)) %>%
                        st_make_valid()

names(et_final) <- names(et_list)

# Check cleaning geometry worked
for(i in 1:length(et_clean_list)){
  geometry_check <- which(st_is_valid(et_clean_list[[i]]) == FALSE)
  print(length(geometry_check))
}

# Check for empty geometry
for(i in 1:length(et_clean_list)){
  empty_test <- which(st_is_empty(et_clean_list[[i]]) == TRUE)
  print(empty_test)
}
```


As for URGR_013, we only select the polygons and discard points and linestrings.
```{r}
#| eval: false
#| code-summary: "Final dataset of ecosystem type"

# Keep only polygon features
et_final <- et_clean_list %>%
              map(\(.) st_collection_extract(.,
                                             type = c("POLYGON"), 
                                             warn = FALSE))

names(et_final) <- names(et_clean_list)
```

The resulting data are quite heavy, it is important to clean the R Environment to free memory space.
```{r}
#| eval: false
#| code-summary: "Clean R Environment"

# Remove non-essential R objects-
rm(list=setdiff(ls(), c("et_clean_list",
                        "urb_domn_lau_32")))

```

#### 9.2.3 Data analyses
We first run an intersection between the urban domains within the LAUs (`urb_domn_lau_32`) and the ecosystem types (`et_clean_list`).
```{r}
#| eval: false
#| code-summary: "Intersection ecosystem types and LAU - urban domains"

et_list_urb_domn <- et_final %>%
                      map(\(.) st_intersection(., urb_domn_lau_32))

names(et_list_urb_domn) <- names(et_final)

et_list_urb_domn_ex <- et_list_urb_domn %>%
                        compact() %>%
                        bind_rows()
```

Now we can calculate the areas of ecosystem types per urban domain within each LAUs.
```{r}
#| eval: false
#| code-summary: "Calculate areas of ecosystems within LAU - urban domains"

et_list_urb_domn <- et_final %>%
                      map(\(.) st_intersection(., urb_domn_lau_32))

names(et_list_urb_domn) <- names(et_final)

et_list_urb_domn_ex <- et_list_urb_domn %>%
                        compact() %>%
                        bind_rows()
```

Then, we calculate the total area of urban domains within each LAU.
```{r}
#| eval: false
#| code-summary: "Total area of  LAU - urban domains"

urb_domn_total_area <- urb_domn_lau_32 %>%
                        mutate(., urb_domn_area_m2 = unclass(st_area(.))) %>%
                        st_drop_geometry() %>%
                        select(LAU_ID, urb_domn_area_m2) %>%
                        group_by(LAU_ID) %>%
                        summarise(urb_domn_total_area = sum(urb_domn_area_m2))
```

Calculate the total area of urban domain within LAU aggregated at the level of four clusters (referred to as "city group" below): Trondheim, Oslo, Stavanger, and Bergen.
```{r}
#| eval: false
#| code-summary: "Group LAU - urban domains into four clusters"

city_group_names <- c("Trondheim", "Oslo", "Stavanger", "Bergen")
city_group_area <- urb_domn_lau_32 %>%
                    mutate(., grp_area_m2 = unclass(st_area(.))) %>%
                    st_drop_geometry() %>%
                    select(cty_grp, grp_area_m2) %>%
                    group_by(cty_grp) %>%
                    summarise(cty_grp_area = sum(grp_area_m2)) %>%
                    cbind(., city_group_names)
                    
```

Finally, we can calculate summary tables for URGR_022:
```{r}
#| eval: false
#| code-summary: "Create summary tables"

# Summary table detailed per LAUs
urgr_022_tab <- et_urbdmn_area %>%
                  compact() %>%
                  bind_rows() %>%
                  st_drop_geometry() %>%
                  select(LAUNAMN, DEGURBA, LAU_ID, cty_grp,
                         okosystemtype_1, okosystemtype_2,
                         okosystemtype_3, okosystemtype_kode,
                         et_area_m2) %>%
                  group_by(cty_grp, LAU_ID, LAUNAMN, okosystemtype_1, okosystemtype_2, okosystemtype_3, okosystemtype_kode) %>%
                  summarise(total_area_et_m2 = sum (et_area_m2)) %>%
                  left_join(., urb_domn_total_area, by = "LAU_ID")

# Summary table aggregated per "city group"
urgr_022_tab_city_gr <- urgr_022_tab %>%
                          group_by(cty_grp, okosystemtype_1, okosystemtype_2, okosystemtype_3, okosystemtype_kode) %>%
                          select(!urb_domn_total_area) %>%
                          summarise(total_area_et_m2 = sum(total_area_et_m2)) %>%
                          left_join(., city_group_area, by = "cty_grp")
```

These table have been exported to the internal repository and will be used in the Results section to create an overall summary table comparing all URGR indicators.

### 9.3 URGR_023
#### 9.3.1 Load and prepare the data
As for URGR_013, we start by loading all the ecosystem types of interest to define urban green spaces. According to the @cond-gn-eurostat, all ecosystem types in the EU Ecosystem Types Typology with a green cover should be included. This means that, in the EU Ecosystem Typology, we only discard: 10. Marine inlets and transitional waters, 12. Marine Ecosystems, and 1. Settlements and Other Artificial areas except classes 1.4 Urban greenspace and 1.5.2 Cemeteries. Note that the new Grunnkart has several tiles and not all of them have the same projection.
```{r}
#| eval: false
#| code-summary: "Create Ecosystem Types datasets"

# Code co-created by Sylvie Clappe and Jennifer E. Hansen
# Path to the Grunnkart data
gdb_folder <- "/data/R/GeoSpatialData/LandUse/Norway_Arealregnskap/Original/GrunnkartArealregnskap FGDB-format"

# List the gdb files
gdb_files <- list.files(gdb_folder, pattern = "_gdb\\.gdb$", 
                        full.names = TRUE)

# Define CRS of the first layer (most common CRS of the gdb files)
gk_crs <- st_read(gdb_files[1], query = "SELECT * FROM arealregnskap LIMIT 500") %>%
            crs()

# Function to read a single filtered file
read_gdb <- function(gdb_path, projection_crs) {
  tryCatch({
    layer <- st_read(dsn = gdb_path, layer = "arealregnskap", query = query_string)
  }, error = function(e) {
    message("Error reading: ", gdb_path, "\n", e)
    return(NULL)  # error handling
  })
  
  if (crs(layer) == projection_crs){
    return(layer)} 
  else{
    layer_proj <- st_transform(layer, crs = projection_crs)
    print(crs(layer_proj))
    return(layer_proj)
  }
}

# Create a list of SQL queries: one per ecosystem type
query_string_list <- list()

query_string_list[[1]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_3 = 'Cemeteries'"
query_string_list[[2]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_2 = 'Urban greenspace'"
query_string_list[[3]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Lakes and reservoirs'"
query_string_list[[4]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Cropland'"
query_string_list[[5]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Grassland'"
query_string_list[[6]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Inland wetlands'"
query_string_list[[7]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Sparsely vegetated ecosystems'"
query_string_list[[8]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Rivers and canals'"
query_string_list[[9]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Coastal beaches, dunes and wetlands'"
query_string_list[[10]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Forest and woodlands'"
query_string_list[[11]] <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Heathland and shrub'"


names(query_string_list) <- c("Cemeteries",
                              "Urban greenspace",
                              "Lakes and reservoirs",
                              "Cropland",
                              "Grassland",
                              "Inland wetland",
                              "Sparsely vegetated ecosystems",
                              "Rives and canals",
                              "Coastal beaches, sand dunes and wetlands",
                              "Forest and woodlands",
                              "Heathland and shrub")

# Run SQL query and store results in a list
for (i in 1: length(query_string_list)){
query_string <- query_string_list[[i]] 

et_data <- gdb_files %>% 
            map(\(.) read_gdb(., projection_crs = gk_crs))  %>% 
            compact() %>%  
            bind_rows()
}

```


To compile URGR_023, we need the Norwegian Local Administrative Units (LAUs) from Eurostat. According to the @cond-gn-eurostat, only LAUs whcih are cities and the LAUs for towns and suburb adjacent to these cities should be selected. We thus used the DEGURBA variable from Eurostat to select the citites (DEGURBA = 1) and towns and suburbs (DEGURBA = 2) that were adjacent to these cities. Below are two codes: (i) one to create the dataset from scratch, and (ii) one that reads the dataset already created and available from NINA's internal repository.

```{r}
#| eval: false
#| code-summary: "Create LAUs dataset"

# Read excel file with Degurba variable and select Norway
path_lau <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_DEGURBA_Eurostat/"
degurba_lau_no <- read_excel(paste0(path_lau, "EU-27-LAU-2024-NUTS-2024.xlsx"), sheet = "NO")

# Select cities towns and suburbs
cities_sub_no <- degurba_lau_no %>%
                  select("LAU NAME NATIONAL", "DEGURBA") %>%
                  filter(DEGURBA == 1 | DEGURBA == 2) %>%
                  as.data.frame()

# Read shapefile and select Norway
path_lau <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_Eurostat/"
lau_eu <- st_read(paste0(path_lau, "LAU_RG_01M_2023_3035.shp"))
lau_no <- lau_eu %>%
           filter(CNTR_CODE == "NO")


# Join cities_sub_no with lau_no
byer_lau <- inner_join(cities_sub_no, 
                       lau_no, 
                       by = join_by("LAU NAME NATIONAL" == "LAU_NAME")) %>%
              st_as_sf()

# Select LAUs with DEGURBA == 1
lau_1 <- byer_lau %>%
          filter(DEGURBA == 1) %>%
          mutate(city_group = c(1, 2, 2, 2, 2, 2, 3, 3, 4))

# Select LAUs with DEGURBA == 2 which are adjacent to lau_1
lau_2 <- byer_lau %>%
          filter(DEGURBA == 2)

lau2_adj_id <- st_touches(lau_1, lau_2) %>%
                unlist() %>%
                unique()

lau_2_adj <- lau_2[lau2_adj_id, ]

# Create a variable to group the four cities and their suburbs
city_group <- vector()
  
for(i in 1:nrow(lau_2_adj)){
  
  if(st_touches(lau_1[1,], lau_2_adj[i,], sparse = FALSE)[,1] == TRUE){
    city_group[i] <- 1
  } 
  else if(TRUE %in% st_touches(lau_1[c(2,3,4,5,6),], lau_2_adj[i,], sparse = FALSE)[,1]){
    city_group[i] <- 2
  }
  else if(TRUE %in% st_touches(lau_1[c(7,8),], lau_2_adj[i,], sparse = FALSE)[,1]){
    city_group[i] <- 3
  }
  else if(st_touches(lau_1[9,], lau_2_adj[i,], sparse = FALSE)[,1] == TRUE){
    city_group[i] <- 4
  } else {city_group[i] <- NA}
}

# Add group variable to LAU adatset
lau_2_adj <- mutate(lau_2_adj, city_group = city_group)

# Final LAUs dataset
lau <- rbind(lau_1, lau_2_adj)

```

```{r}
#| eval: false
#| code-summary: "Upload LAUs from NINA's internal repository"

# Path to the data
path_boundaries<- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_URGR/"

# Load the data
lau <- st_read(paste0(path_boundaries, "LAUs_URGR.shp"))
```

Finally, to define the settlements of the LAUs, we need the category "1. Settlements and other artificial areas" (SOAA) defined by EU Ecosystem Typology. We take this class from the Grunnkart.
```{r}
#| eval: false
#| code-summary: "Create a SOAA layer"

query_string <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Settlements and other artificial areas'"

soaa <- gdb_files %>% 
          map(\(.) read_gdb(., projection_crs = gk_crs))  %>% 
          compact() %>%  
          bind_rows()
```


#### 9.3.2 Data cleaning
Not all of our data have the same CRS, we need to check so we know if we have to re-project in the subsequent analyses.
```{r}
#| eval: false
#| code-summary: "Check CRS"

# ETs from Grunnkart (we take one as they have all the same CRS)
cemeteries_crs <- crs(et_list[[1]])

# LAUs
lau_crs <- crs(lau)

# SOAA
soaa_crs <- crs(soaa)

# Check they are the same
cemeteries_crs == lau_crs
cemeteries_crs == soaa_crs
```

Once we have done that, we can perform the geometrical and topological checks of the data, and fix any issues that might arise.
```{r}
#| eval: false
#| code-summary: "Geometry and topology - check and fix"
# Check for empty geometry
for(i in 1:length(et_list)){
  empty_test <- which(st_is_empty(et_list[[i]]) == TRUE)
  print(empty_test)
}

urb_domn_lau_32_empty <- which(st_is_empty(urb_domn_lau_32) == TRUE)

# Check validity
for(i in 1:length(et_list)){
  validity_test <- which(st_is_valid(et_list[[i]]) == FALSE)
  print(length(validity_test))
}

urb_domn_lau_32_invalid <- which(st_is_valid(urb_domn_lau_32) == FALSE)

# Clean geometry of ETs with st_make_valid()
et_clean_list <- list()
for(i in c(seq(1,6,1), seq(8,11,1))){
  et_clean <- st_make_valid(et_list[[i]])
  et_clean_list[[i]] <- et_clean
}

et_clean_list[[7]] <- st_buffer(et_list[[7]], 0) %>%
                        filter(!st_is_empty(.)) %>%
                        st_make_valid()

names(et_final) <- names(et_list)

# Check cleaning geometry worked
for(i in 1:length(et_clean_list)){
  geometry_check <- which(st_is_valid(et_clean_list[[i]]) == FALSE)
  print(length(geometry_check))
}

# Check for empty geometry
for(i in 1:length(et_clean_list)){
  empty_test <- which(st_is_empty(et_clean_list[[i]]) == TRUE)
  print(empty_test)
}
```


As for URGR_013, we only select the polygons and discard points and linestrings.
```{r}
#| eval: false
#| code-summary: "Final dataset of ecosystem type"

# Keep only polygon features
et_final <- et_clean_list %>%
                map(\(.) st_collection_extract(.,
                                              type = c("POLYGON"), 
                                             warn = FALSE))

names(et_final) <- names(et_clean_list)


soaa_final <- st_collection_extract(soaa_cln,
                                    type = c("POLYGON"), 
                                    warn = FALSE)
```

Now that the SOAA data have been cleaned, we can create the boundaries of urban areas that we will use for the analyses. For this we first have to re-project the LAU layer to the same CRS as SOAA. Then we can intersect the two layers, and finally dissolve the polygons to only have one overall SOAA polygon per LAU.
```{r}
#| eval: false
#| code-summary: "Create the SOAA boundary for analyses"

# Re-project LAUs in Grunnkart CRS
lau_32 <- st_transform(lau, cemeteries_crs)

# Intersection lau_32 and sooa_urb_cln 
soaa_lau_32 <- st_intersection(soaa_final, lau_32)

# Dissolve soaa_lau_32 boundaries
soaa_poly_final <- soaa_lau_32 %>%
                      group_by(cty_grp, LAU_ID, LAUNAMN, DEGURBA)%>%
                      summarise() %>%
                      as.data.frame() %>%
                      st_as_sf()
```

The resulting data are quite heavy, it is important to clean the R Environment to free memory space.
```{r}
#| eval: false
#| code-summary: "Clean R Environment"

# Remove non-essential R objects-
rm(list=setdiff(ls(), c("et_clean_list",
                        "soaa_final",
                        "soaa_poly_final")))

```


#### 9.3.3 Data analyses
We first run an intersection between the settlements within the LAUs (`soaa_poly_final`) and the ecosystem types (`et_clean_list`).
```{r}
#| eval: false
#| code-summary: "Intersection ecosystem types and the settlemenst within LAUs"

et_soaa <- et_final%>%
            map(\(.) st_intersection(., soaa_poly_final))
```

Now we can calculate the total area of settlements within LAUs.
```{r}
#| eval: false
#| code-summary: "Total area of settlements within LAUs"

soaa_total_area <- soaa_poly_final %>%
                        mutate(., soaa_area_m2 = unclass(st_area(.))) %>%
                        st_drop_geometry() %>%
                        select(LAU_ID, soaa_area_m2) %>%
                        group_by(LAU_ID) %>%
                        summarise(soaa_total_area_m2 = sum(soaa_area_m2))
```

Then, we calculate the total area of settlements within LAU aggregated at the level of four clusters (referred to as "city group" below): Trondheim, Oslo, Stavanger, and Bergen.
```{r}
#| eval: false
#| code-summary: "Group settlemenst within LAUs into four clusters"

city_group_names <- c("Trondheim", "Oslo", "Stavanger", "Bergen")
city_group_area <- soaa_poly_final %>%
                    mutate(., grp_area_m2 = unclass(st_area(.))) %>%
                    st_drop_geometry() %>%
                    select(cty_grp, grp_area_m2) %>%
                    group_by(cty_grp) %>%
                    summarise(cty_grp_total_area_m2 = sum(grp_area_m2)) %>%
                    cbind(., city_group_names)
                    
```

Finally, we can calculate summary tables for URGR_023:
```{r}
#| eval: false
#| code-summary: "Create summary tables"

# Summary table detailed per LAUs
urgr_023_tab <- et_soaa%>%
                  compact() %>%
                  bind_rows() %>%
                  mutate(et_area_m2 = unclass(st_area(.))) %>%
                  st_drop_geometry() %>%
                  select(LAUNAMN, DEGURBA, LAU_ID, cty_grp,
                         okosystemtype_1, okosystemtype_2,
                         okosystemtype_3, okosystemtype_kode,
                         et_area_m2) %>%
                  group_by(cty_grp, LAU_ID, LAUNAMN, okosystemtype_1, okosystemtype_2, okosystemtype_3, okosystemtype_kode) %>%
                  summarise(total_area_et_m2 = sum (et_area_m2))%>%
                  left_join(., soaa_total_area, by = "LAU_ID")

# Summary table aggregated per "city group"
urgr_023_tab_city_gr <- urgr_023_tab %>%
                          group_by(cty_grp, okosystemtype_1, okosystemtype_2, okosystemtype_3, okosystemtype_kode) %>%
                          select(!soaa_total_area_m2) %>%
                          summarise(total_area_et_m2 = sum(total_area_et_m2)) %>%
                          left_join(., city_group_area, by = "cty_grp")
```

These table have been exported to the internal repository and will be used in the Results section to create an overall summary table comparing all URGR indicators.

### 9.4 URGR_025
#### 9.4.1 Load and prepare the data
We start by loading the Corine Land Cover data and filter the categories that correspond to the EU Ecosystem Typology class 1. Settlements and other artificial areas (SOAA).
```{r}
#| eval: false
#| code-summary: "Create Ecosystem Types datasets"

# Read CLC2018
path_clc <- "/data/R/GeoSpatialData/LandCover/Norway_CORINE_Landcover/Original/CORINE_2018/"
clc18 <- st_read(paste0(path_clc, "0000_32632_corine2018_8d4abc_SHAPE.shp"))

# Extract Settlements and Other Artificial Areas
clc18_soaa <- clc18 %>%
                filter(clc18_kode == 111 |
                clc18_kode == 112 |
                clc18_kode == 121 |
                clc18_kode == 122 |
                clc18_kode == 123 |
                clc18_kode == 131 |
                clc18_kode == 132 |
                clc18_kode == 133 |
                clc18_kode == 141 |
                clc18_kode == 142 )

```


To compile URGR_025, we need the Norwegian Local Administrative Units (LAUs) from Eurostat. According to the @cond-gn-eurostat, only LAUs whcih are cities and the LAUs for towns and suburb adjacent to these cities should be selected. We thus used the DEGURBA variable from Eurostat to select the cities (DEGURBA = 1) and towns and suburbs (DEGURBA = 2) that were adjacent to these cities. Below are two codes: (i) one to create the dataset from scratch, and (ii) one that reads the dataset already created and available from NINA's internal repository.

```{r}
#| eval: false
#| code-summary: "Create LAUs dataset"

# Read excel file with Degurba variable and select Norway
path_lau <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_DEGURBA_Eurostat/"
degurba_lau_no <- read_excel(paste0(path_lau, "EU-27-LAU-2024-NUTS-2024.xlsx"), sheet = "NO")

# Select cities towns and suburbs
cities_sub_no <- degurba_lau_no %>%
                  select("LAU NAME NATIONAL", "DEGURBA") %>%
                  filter(DEGURBA == 1 | DEGURBA == 2) %>%
                  as.data.frame()

# Read shapefile and select Norway
path_lau <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_Eurostat/"
lau_eu <- st_read(paste0(path_lau, "LAU_RG_01M_2023_3035.shp"))
lau_no <- lau_eu %>%
           filter(CNTR_CODE == "NO")


# Join cities_sub_no with lau_no
byer_lau <- inner_join(cities_sub_no, 
                       lau_no, 
                       by = join_by("LAU NAME NATIONAL" == "LAU_NAME")) %>%
              st_as_sf()

# Select LAUs with DEGURBA == 1
lau_1 <- byer_lau %>%
          filter(DEGURBA == 1) %>%
          mutate(city_group = c(1, 2, 2, 2, 2, 2, 3, 3, 4))

# Select LAUs with DEGURBA == 2 which are adjacent to lau_1
lau_2 <- byer_lau %>%
          filter(DEGURBA == 2)

lau2_adj_id <- st_touches(lau_1, lau_2) %>%
                unlist() %>%
                unique()

lau_2_adj <- lau_2[lau2_adj_id, ]

# Create a variable to group the four cities and their suburbs
city_group <- vector()
  
for(i in 1:nrow(lau_2_adj)){
  
  if(st_touches(lau_1[1,], lau_2_adj[i,], sparse = FALSE)[,1] == TRUE){
    city_group[i] <- 1
  } 
  else if(TRUE %in% st_touches(lau_1[c(2,3,4,5,6),], lau_2_adj[i,], sparse = FALSE)[,1]){
    city_group[i] <- 2
  }
  else if(TRUE %in% st_touches(lau_1[c(7,8),], lau_2_adj[i,], sparse = FALSE)[,1]){
    city_group[i] <- 3
  }
  else if(st_touches(lau_1[9,], lau_2_adj[i,], sparse = FALSE)[,1] == TRUE){
    city_group[i] <- 4
  } else {city_group[i] <- NA}
}

# Add group variable to LAU adatset
lau_2_adj <- mutate(lau_2_adj, city_group = city_group)

# Final LAUs dataset
lau <- rbind(lau_1, lau_2_adj)

```

```{r}
#| eval: false
#| code-summary: "Upload LAUs from NINA's internal repository"

# Path to the data
path_boundaries<- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_URGR/"

# Load the data
lau <- st_read(paste0(path_boundaries, "LAUs_URGR.shp"))
```

Finally, to define the urban green areas of the settlements within the LAUs, we need the Imperviousness layer from Copernicus. The rationale is that any areas that are not impervious within the settlements of LAUs, are green or blue urban areas. Impervious Copernicus layer is however constituted of tiles, which need to be assemble into a virtual raster to be used for analyses. Below, we present two codes: (i) create the Imperviousness Copernicus virtual raster from scratch, and (ii) read the Imperviousness Copernicus virtual raster directly from NINA's internal repository.
```{r}
#| eval: false
#| code-summary: "Create the Imperviousness Copernicus virtutal raster"

# Create a list of the Copernicus raster tiles
path_cop <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/IMD_2018_010m_no_03035_v020/DATA"
filename_list_imp <- list.files(path = path_cop, pattern = '.tif$', 
                                all.files = TRUE, full.names = TRUE)

# Create the virtual raster
imper_cop_vrt <- vrt(filename_list_imp, 
                     filename = paste0(path_imp, "/imper_cop.vrt")) 
```

```{r}
#| eval: false
#| code-summary: "Upload the Imperviousness Copernicus virtual raster"

# Path to the data
path_imp <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/IMD_2018_010m_no_03035_v020/DATA/"

# Load the data
imper_cop_vrt <- rast(paste0(path_imp, "imper_cop.vrt"))
```

#### 9.4.2 Data cleaning
Not all of our data have the same CRS, we need to check so we know if we have to re-project in the subsequent analyses.
```{r}
#| eval: false
#| code-summary: "Check CRS"

# LAUs
lau_crs <- crs(lau)

# SOAA
soaa_crs <- crs(clc18_soaa)

# Imperviousness Copernicus
imper_vrt_crs <- crs(imper_cop_vrt)

# Check they are the same
imper_vrt_crs == lau_crs
imper_vrt_crs == soaa_crs
soaa_crs == lau_crs
```

Once we have done that, we can perform the geometrical and topological checks of the data, and fix any issues that might arise.
```{r}
#| eval: false
#| code-summary: "Geometry and topology - check and fix"

# Check for empty geometry
soaa_clc_empty <- which(st_is_empty(clc18_soaa) == TRUE)
lau_empty <- which(st_is_empty(lau) == TRUE)

# Check validity
soaa_clc_invalid <- which(st_is_valid(clc18_soaa) == FALSE)
lau_invalid <- which(st_is_valid(lau) == FALSE)
```

Now we can create the boundaries for the urban areas by intersecting the LAUs layer with the settlements layer from Corine Land Cover. THis will result in a layer of settelemenst per LAUs and will be the final boundary to be used in the subsequent analyses.
```{r}
#| eval: false
#| code-summary: "Create SOAA boundary for analyses"

# Re-project LAUs in CLC CRS
lau_32 <- st_transform(lau, soaa_crs)

# Intersection lau_32 and sooa_urb_cln 
soaa_lau_32 <- st_intersection(clc18_soaa, lau_32)
```

Contrary to the other indicators using the Grunnkart, we don't need to select the polygons and discard points and linestrings. Corine Land Cover data are only composed of polygons. As previously, good practice is to clean the R Environment to free memory space.
```{r}
#| eval: false
#| code-summary: "Clean R Environment"

# Remove non-essential R objects-
rm(list=setdiff(ls(), c("et_clean_list",
                        "soaa_lau_32",
                        "imper_cop_vrt")))

```


#### 9.4.3 Data analyses
We first re-project the boundary `soaa_lau_32` to match the CRS of the Imperviousnes Copernicus layer `imper_cop_vrt`. Note that it is good practice to avoid re-projecting rasters as it leads to biases in areas.
```{r}
#| eval: false
#| code-summary: "Re-project the SOAA boundary"

soaa_lau_89 <- st_transform(soaa_lau_32, crs(imper_cop_vrt))
```

Now we can use `exact_extract()` to extract the pixels from the Imperviousness Copernicus layer that overlap with our SOAA boundary. Note that `exact_extract()` does not output spatial data but a summary dataframe. That is why we calculate the areas of all SOAA polygons before, and then export a dataframe that summarises the mean percentage of imperviousness per polygon. Both piece of information will later allow to calculate the impervious and non-impervious areas.
```{r}
#| eval: false
#| code-summary: "Calculate SOAA area and extract mean % imperviousness"

soaa_lau_imper_final <- soaa_lau_89 %>%
                            mutate(soaa_area_m2 = unclass(st_area(.))) %>%
                            exact_extract(imper_cop_vrt,
                                          .,
                                          fun = c("mean"),
                                          append_cols = TRUE)
```

Now we can calculate the impervious and non-impervious areas of SOAA within the LAUs. The impervious area is compiled by multiplying the area of the SOAA polygons by their corresponding mean percentage of imperviousness. The non-impervious areas are calculated as: 1 - impervious area.
```{r}
#| eval: false
#| code-summary: "Calculate SOAA impervious and non-impervious areas"

soaa_imper_area_lau <- soaa_lau_imper_final %>%
                        mutate(imper_area_mean = soaa_area_m2 * mean/100,
                        non_imper_area_mean = soaa_area_m2 - imper_area_mean)
```

Finally, we can produce some summary tables for URGR_025. Note that two tables are produced: (i) one per LAUs; (ii) one per cluster of LAUs (referred to as "city group" below) comprising Trondheim, Oslo, Stavanger, and Bergen.

```{r}
#| eval: false
#| code-summary: "Create summary tables"

# Calculate summary table per LAUs
urgr_025_tab <- soaa_imper_area_lau %>%
                  select(LAUNAMN, DEGURBA, LAU_ID, cty_grp,
                         clc18_kode, soaa_area_m2, imper_area_mean, non_imper_area_mean) %>%
                  group_by(cty_grp, LAU_ID, LAUNAMN) %>%
                  summarise(total_imper_area_m2 = sum(imper_area_mean),
                            total_non_imper_area_m2 = sum(non_imper_area_mean),
                            total_soaa_area_m2 = sum(soaa_area_m2))

# Calculate summary table per city group
city_group_names <- c("Trondheim", "Oslo", "Stavanger", "Bergen")
urgr_025_tab_city_gr <- urgr_025_tab %>%
                          group_by(cty_grp) %>%
                          summarise(total_imper_area_m2 = sum(total_imper_area_m2),
                                    total_non_imper_area_m2 = sum(total_non_imper_area_m2),
                                    total_cty_grp_area_m2 = sum(total_soaa_area_m2)) %>%
                          cbind(., city_group_names)
```


These table have been exported to the internal repository and will be used in the Results section to create an overall summary table comparing all URGR indicators.

### 9.5 URGR_030
#### 9.6.1 Load and prepare the data
We start by loading the Settlements and other artificial areas (SOAA) class of the Grunnkart. 
```{r}
#| eval: false
#| code-summary: "Create SOAA layer"

# Code co-created by Sylvie Clappe and Jennifer E. Hansen
# File path to grunnkart
gdb_folder <- "/data/R/GeoSpatialData/LandUse/Norway_Arealregnskap/Original/GrunnkartArealregnskap FGDB-format"

# pattern for stored gdb
gdb_files <- list.files(gdb_folder, pattern = "_gdb\\.gdb$", 
                        full.names = TRUE)

# Define SQL query
query_string <- "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Settlements and other artificial areas'"

# Define CRS for all Grunnkart layers
gk_crs <- st_read(gdb_files[1], query = "SELECT * FROM arealregnskap LIMIT 10") %>%
            crs()

# Function to read a single filtered file and re-project it
read_gdb <- function(gdb_path, projection_crs) {
  tryCatch({
    layer <- st_read(dsn = gdb_path, layer = "arealregnskap", query = query_string)
  }, error = function(e) {
    message("Error reading: ", gdb_path, "\n", e)
    return(NULL)  # error handling
  })
  
  if (crs(layer) == projection_crs){
    return(layer)} 
  else{
    layer_proj <- st_transform(layer, crs = projection_crs)
    print(crs(layer_proj))
    return(layer_proj)
  }
}

# Apply the function to all .gdb files and combine
soaa <- gdb_files %>% 
          map(\(.) read_gdb(., projection_crs = gk_crs))  %>% 
          compact() %>%  
          bind_rows()

```


To compile URGR_030, we need the fylke boundaries to fylke and regional levels. We load the fylke boundaries provided by Kartverkert. As these do not have regional information, we build a dataset with the regional code and names that we will be able to join together later on when we build the summary tables. The reason we do not have a shapefile with the fylke and an additional column with the regions is that it increases significantly the size of the file. Below are two version of this code: (i) build the excel file from scratch, and (ii) load in the excel file already created from the NINA's internal repository.

```{r}
#| eval: false
#| code-summary: "Upload fylke boundaries and create the fylke-region dataset"

# Read Fylke - Kommune excel file from Kartverkert
path_boundaries<- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/NO_Fylke/"
fylke <- read_excel(paste0(path_boundaries, "kommune_fylke_NO_2024.xlsx")) %>%
          as.data.frame()
colnames(fylke) <- c("fylke_nm",
                     "fylke_nr",
                     "kommune_nm",
                     "kommune_nr_2024",
                     "kommune_nr_2023")

# Create the dataframe with Regional information
region_fylke_id <- data.frame(region_name = c("nord_norge", 
                                              "nord_norge",
                                              "nord_norge",
                                              "midt_norge",
                                              "vestlandet",
                                              "vestlandet",
                                              "vestlandet",
                                              "solandet",
                                              "ostlandet",
                                              "ostlandet",
                                              "ostlandet",
                                              "ostlandet",
                                              "ostlandet",
                                              "ostlandet",
                                              "ostlandet"),
                              fylkesnumm = c(55,
                                             56,
                                             18,
                                             50,
                                             11,
                                             15,
                                             46,
                                             42,
                                             39,
                                             40,
                                             33,
                                             32,
                                             31,
                                             34,
                                             03))

# Join the boundaries with regional information
adminb_no <-  fylke %>%
                full_join(., region_fylke_id, 
                          by = join_by("fylke_nr" == "fylkesnumm"))

```

```{r}
#| eval: false
#| code-summary: "Upload fylke boundaries and fylke-region dataset from NINA's internal repository"

# Read files
path_boundaries<- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/NO_Fylke/"
admin_bd <- read_excel(paste0(path_boundaries, "kommune_fylke_region_NO_2024.xlsx"))
fylke <- st_read(paste0(path_boundaries, "Norway_Fylke_2024.shp"))

```

Finally, to define the urban green areas of the SOAA, we need the Imperviousness layer from Copernicus. The rationale is that any areas that are not impervious within the SOAA, are green or blue urban areas. Impervious Copernicus layer is however constituted of tiles, which need to be assemble into a virtual raster to be used for analyses. Below, we present two codes: (i) create the Imperviousness Copernicus virtual raster from scratch, and (ii) read the Imperviousness Copernicus virtual raster directly from NINA's internal repository.
```{r}
#| eval: false
#| code-summary: "Create the Imperviousness Copernicus virtutal raster"

# Create a list of the Copernicus raster tiles
path_cop <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/IMD_2018_010m_no_03035_v020/DATA"
filename_list_imp <- list.files(path = path_cop, pattern = '.tif$', 
                                all.files = TRUE, full.names = TRUE)

# Create the virtual raster
imper_cop_vrt <- vrt(filename_list_imp, 
                     filename = paste0(path_imp, "/imper_cop.vrt")) 
```

```{r}
#| eval: false
#| code-summary: "Upload the Imperviousness Copernicus virtual raster"

# Path to the data
path_imp <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/IMD_2018_010m_no_03035_v020/DATA/"

# Load the data
imper_cop_vrt <- rast(paste0(path_imp, "imper_cop.vrt"))
```

#### 9.6.2 Data cleaning
Not all of our data have the same CRS, we need to check so we know if we have to re-project in the subsequent analyses.
```{r}
#| eval: false
#| code-summary: "Check CRS"

# SOAA
soaa_crs <- crs(soaa)

# Imperviousness Copernicus
imper_vrt_crs <- crs(imper_cop_vrt)

# Fylke
fylke_crs <- crs(fylke)

# Check they are the same
imper_vrt_crs == fylke_crs
imper_vrt_crs == soaa_crs
soaa_crs == fylke_crs
```

Once we have done that, we can perform the geometrical and topological checks of the data, and fix any issues that might arise.
```{r}
#| eval: false
#| code-summary: "Geometry and topology - check and fix"

# Check for empty geometry
soaa_empty <- which(st_is_empty(soaa) == TRUE)
fylke_empty <- which(st_is_empty(fylke) == TRUE)

# Check validity
soaa_invalid <- which(st_is_valid(soaa) == FALSE)
fylke_invalid <- which(st_is_valid(fylke) == FALSE)

# Re-project soaa_lau_32 into Imperviousness Copernicus layer CRS
# we re-project first as sometimes it helps fixing geometry and typology issues
soaa_89 <- st_transform(soaa, crs(imper_cop_vrt))

# Clean SOAA geometry
soaa_89_cln <- st_make_valid(soaa_89)

# Check soaa_cln
soaa_empty <- which(st_is_empty(soaa_89_cln) == TRUE)
soaa_invalid <- which(st_is_valid(soaa_89_cln) == FALSE)
```

As previously, good practice is to clean the R Environment to free memory space.
```{r}
#| eval: false
#| code-summary: "Clean R Environment"

# Remove non-essential R objects-
rm(list=setdiff(ls(), c("soaa_89_cln",
                        "fylke",
                        "imper_cop_vrt")))

```

#### 9.6.3 Data analyses
We first intersect `soaa_89_cln` with the `fylke`. Prior to that, note that we (i) select only the polygons of `soaa_89_cln`; (ii) re-projected `fylke` to match the CRS from `soaa_89_cln`; (iii) calculate the areas resulting from the intersections. The reason behind extracting the polygons only is that the subsequent analyses required `extact_extract()` function, which only works with polygon geometry.

```{r}
#| eval: false
#| code-summary: "Intersection SOAA and fylke boundary"

# Only keep polygons from soaa_89 as exact_extract() doesn't work with
# linestrings and points
soaa_89_final <- soaa_89_cln  %>%
                    st_collection_extract(.,
                                          type = c("POLYGON"), 
                                          warn = FALSE)

# Re-projection
fylke_89 <- st_transform(fylke, crs(soaa_89_final))

# Intersection
soaa_fylke_89 <- st_intersection(soaa_89_final, fylke_89) %>%
                      mutate(soaa_area_m2 = unclass(st_area(.)))

# Re-extract polygons only as the intersection created linestrings
soaa_fylke_89_final <- soaa_fylke_89  %>%
                        st_collection_extract(.,
                        type = c("POLYGON"), 
                        warn = FALSE)
```

Now we can use `exact_extract()` to extract the pixels from the Imperviousness Copernicus layer that overlap with `soaa_fylke_89_final`. Note that `exact_extract()` does not output spatial data but a summary dataframe. That is why we calculate the areas of all SOAA polygons before, and then export a dataframe that summarises the mean percentage of imperviousness per polygon. Both piece of information will later allow to calculate the impervious and non-impervious areas.
```{r}
#| eval: false
#| code-summary: "Calculate SOAA area and extract mean % imperviousness"

soaa_fylke_imper <-  exact_extract(imper_cop_vrt,
                                   soaa_fylke_89_final,
                                   fun = c("mean"),
                                   append_cols = TRUE)
```

Now we can calculate the impervious and non-impervious areas of SOAA within fylke. The impervious area is compiled by multiplying the area of the SOAA polygons by their corresponding mean percentage of imperviousness. The non-impervious areas are calculated as: 1 - impervious area.
```{r}
#| eval: false
#| code-summary: "Calculate SOAA impervious and non-impervious areas"

soaa_imper_area<- soaa_fylke_imper %>%
                    mutate(imper_area_mean = soaa_area_m2 * mean/100,
                    non_imper_area_mean = soaa_area_m2 - imper_area_mean)

```

Finally, we can produce some summary tables for URGR_31. Note that two tables are produced: (i) one per fylke; (ii) one per region.

```{r}
#| eval: false
#| code-summary: "Create summary tables"

# Calculate summary table per fylke
urgr_030_tab <- soaa_imper_area %>%
                    select(fylkesnumm, fylkesnavn, soaa_area_m2, 
                            imper_area_mean, non_imper_area_mean) %>%
                    group_by(fylkesnumm, fylkesnavn) %>%
                    summarise(total_imper_area_m2 = sum(imper_area_mean),
                              total_non_imper_area_m2 = sum(non_imper_area_mean),
                              total_soaa_area_m2 = sum(soaa_area_m2))

# Calculate summary table per region
urgr_030_tab$fylkesnumm <- as.numeric(urgr_030_tab$fylkesnumm)
urgr_030_tab_region <- urgr_030_tab %>%
                        left_join(., 
                                  admin_bd, 
                                  join_by(fylkesnumm == fylke_nr)) %>%
                        group_by(region_name) %>%
                        summarise(total_imper_area_m2 = sum(total_imper_area_m2),
                                  total_non_imper_area_m2 = sum(total_non_imper_area_m2),
                                  total_cty_grp_area_m2 = sum(total_soaa_area_m2))
```


### 9.6 URGR_031
#### 9.6.1 Load and prepare the data
We start by loading the Corine Land Cover data and filter the categories that correspond to the EU Ecosystem Typology class 1. Settlements and other artificial areas (SOAA).
```{r}
#| eval: false
#| code-summary: "Create SOAA layer"

# Read CLC2018
path_clc <- "/data/R/GeoSpatialData/LandCover/Norway_CORINE_Landcover/Original/CORINE_2018/"
clc18 <- st_read(paste0(path_clc, "0000_32632_corine2018_8d4abc_SHAPE.shp"))

# Extract Settlements and Other Artificial Areas
clc18_soaa <- clc18 %>%
                filter(clc18_kode == 111 |
                clc18_kode == 112 |
                clc18_kode == 121 |
                clc18_kode == 122 |
                clc18_kode == 123 |
                clc18_kode == 131 |
                clc18_kode == 132 |
                clc18_kode == 133 |
                clc18_kode == 141 |
                clc18_kode == 142 )

```


To compile URGR_031, we need the fylke boundaries to fylke and regional levels. We load the fylke boundaries provided by Kartverkert. As these do not have regional information, we build a dataset with the regional code and names that we will be able to join together later on when we build the summary tables. The reason we do not have a shapefile with the fylke and an additional column with the regions is that it increases significantly the size of the file. Below are two version of this code: (i) build the excel file from scratch, and (ii) load in the excel file already created from the NINA's internal repository.

```{r}
#| eval: false
#| code-summary: "Upload fylke boundaries and create the fylke-region dataset"

# Read Fylke - Kommune excel file from Kartverkert
path_boundaries<- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/NO_Fylke/"
fylke <- read_excel(paste0(path_boundaries, "kommune_fylke_NO_2024.xlsx")) %>%
          as.data.frame()
colnames(fylke) <- c("fylke_nm",
                     "fylke_nr",
                     "kommune_nm",
                     "kommune_nr_2024",
                     "kommune_nr_2023")

# Create the dataframe with Regional information
region_fylke_id <- data.frame(region_name = c("nord_norge", 
                                              "nord_norge",
                                              "nord_norge",
                                              "midt_norge",
                                              "vestlandet",
                                              "vestlandet",
                                              "vestlandet",
                                              "solandet",
                                              "ostlandet",
                                              "ostlandet",
                                              "ostlandet",
                                              "ostlandet",
                                              "ostlandet",
                                              "ostlandet",
                                              "ostlandet"),
                              fylkesnumm = c(55,
                                             56,
                                             18,
                                             50,
                                             11,
                                             15,
                                             46,
                                             42,
                                             39,
                                             40,
                                             33,
                                             32,
                                             31,
                                             34,
                                             03))

# Join the boundaries with regional information
adminb_no <-  fylke %>%
  full_join(., region_fylke_id, 
            by = join_by("fylke_nr" == "fylkesnumm"))

```

```{r}
#| eval: false
#| code-summary: "Upload fylke boundaries and fylke-region dataset from NINA's internal repository"

# Read files
path_boundaries<- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/NO_Fylke/"
admin_bd <- read_excel(paste0(path_boundaries, "kommune_fylke_region_NO_2024.xlsx"))
fylke <- st_read(paste0(path_boundaries, "Norway_Fylke_2024.shp"))

```

Finally, to define the urban green areas of the SOAA, we need the Imperviousness layer from Copernicus. The rationale is that any areas that are not impervious within the SOAA, are green or blue urban areas. Impervious Copernicus layer is however constituted of tiles, which need to be assemble into a virtual raster to be used for analyses. Below, we present two codes: (i) create the Imperviousness Copernicus virtual raster from scratch, and (ii) read the Imperviousness Copernicus virtual raster directly from NINA's internal repository.
```{r}
#| eval: false
#| code-summary: "Create the Imperviousness Copernicus virtutal raster"

# Create a list of the Copernicus raster tiles
path_cop <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/IMD_2018_010m_no_03035_v020/DATA"
filename_list_imp <- list.files(path = path_cop, pattern = '.tif$', 
                                all.files = TRUE, full.names = TRUE)

# Create the virtual raster
imper_cop_vrt <- vrt(filename_list_imp, 
                     filename = paste0(path_imp, "/imper_cop.vrt")) 
```

```{r}
#| eval: false
#| code-summary: "Upload the Imperviousness Copernicus virtual raster"

# Path to the data
path_imp <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/IMD_2018_010m_no_03035_v020/DATA/"

# Load the data
imper_cop_vrt <- rast(paste0(path_imp, "imper_cop.vrt"))
```

#### 9.6.2 Data cleaning
Not all of our data have the same CRS, we need to check so we know if we have to re-project in the subsequent analyses.
```{r}
#| eval: false
#| code-summary: "Check CRS"

# Fylke
fylke_crs <- crs(fylke)

# SOAA
soaa_crs <- crs(clc18_soaa)

# Imperviousness Copernicus
imper_vrt_crs <- crs(imper_cop_vrt)

# Check they are the same
imper_vrt_crs == fylke_crs
imper_vrt_crs == soaa_crs
soaa_crs == fylke_crs
```

Once we have done that, we can perform the geometrical and topological checks of the data, and fix any issues that might arise.
```{r}
#| eval: false
#| code-summary: "Geometry and topology - check and fix"

# Check for empty geometry
soaa_clc_empty <- which(st_is_empty(clc18_soaa) == TRUE)
fylke_empty <- which(st_is_empty(fylke) == TRUE)

# Check validity
soaa_clc_invalid <- which(st_is_valid(clc18_soaa) == FALSE)
fylke_invalid <- which(st_is_valid(fylke) == FALSE)
```

Contrary to the other indicators using the Grunnkart, we don't need to select the polygons and discard points and linestrings. Corine Land Cover data are only composed of polygons. As previously, good practice is to clean the R Environment to free memory space.
```{r}
#| eval: false
#| code-summary: "Clean R Environment"

# Remove non-essential R objects-
rm(list=setdiff(ls(), c("clc18_soaa",
                        "fylke",
                        "imper_cop_vrt",
                        "admin_bd")))

```


#### 9.6.3 Data analyses
We first re-project the SOAA `clc18_soaa` and fylke boundaries `fylke` to match the CRS of the Imperviousness Copernicus layer `imper_cop_vrt`. Note that it is good practice to avoid re-projecting rasters as it leads to biases in areas.
```{r}
#| eval: false
#| code-summary: "Re-project the SOAA and fylke boundary"

clc18_soaa_89 <- st_transform(clc18_soaa, crs(imper_cop_vrt))

fylke_89 <- st_transform(fylke, crs(imper_cop_vrt))
```

Now we can perform an intersection between `clc18_soaa` and `fylke`to have the results disaggregated at fylke level.
```{r}
#| eval: false
#| code-summary: "Intersection SOAA and fylke boundary"

fylke_soaa_89 <- st_intersection(clc18_soaa_89, fylke_89)
```

Now we can use `exact_extract()` to extract the pixels from the Imperviousness Copernicus layer that overlap with our SOAA boundary. Note that `exact_extract()` does not output spatial data but a summary dataframe. That is why we calculate the areas of all SOAA polygons before, and then export a dataframe that summarises the mean percentage of imperviousness per polygon. Both piece of information will later allow to calculate the impervious and non-impervious areas.
```{r}
#| eval: false
#| code-summary: "Calculate SOAA area and extract mean % imperviousness"

fylke_soaa_imper <- fylke_soaa_89 %>%
                      mutate(soaa_area_m2 = unclass(st_area(.))) %>%
                      exact_extract(imper_cop_vrt,
                                    .,
                                    fun = c("mean"),
                                    append_cols = TRUE)
```

Now we can calculate the impervious and non-impervious areas of SOAA within fylke. The impervious area is compiled by multiplying the area of the SOAA polygons by their corresponding mean percentage of imperviousness. The non-impervious areas are calculated as: 1 - impervious area.
```{r}
#| eval: false
#| code-summary: "Calculate SOAA impervious and non-impervious areas"

fylke_soaa_imper_area <- fylke_soaa_imper %>%
                          mutate(imper_area_mean = soaa_area_m2 * mean/100,
                          non_imper_area_mean = soaa_area_m2 - imper_area_mean)
```

Finally, we can produce some summary tables for URGR_31. Note that two tables are produced: (i) one per fylke; (ii) one per region.

```{r}
#| eval: false
#| code-summary: "Create summary tables"

# Calculate summary table per fylke
urgr_031_tab_fylke <- fylke_soaa_imper_area %>%
                        select(fylkesnumm, fylkesnavn, clc18_kode, soaa_area_m2,
                                imper_area_mean, non_imper_area_mean) %>%
                        group_by(fylkesnumm, fylkesnavn) %>%
                        summarise(total_imper_area_m2 = sum(imper_area_mean),
                                  total_non_imper_area_m2 = sum(non_imper_area_mean),
                                  total_soaa_area_m2 = sum(soaa_area_m2))

# Calculate summary table per region
urgr_031_tab_fylke$fylkesnumm <- as.numeric(urgr_031_tab_fylke$fylkesnumm)
urgr_031_tab_region <- urgr_031_tab_fylke %>%
                          left_join(., 
                                    admin_bd[, c("fylke_nr", "region_name")], 
                                    join_by(fylkesnumm == fylke_nr)) %>%
                          group_by(region_name) %>%
                          summarise(total_imper_area_m2 = sum(total_imper_area_m2),
                                    total_non_imper_area_m2 = sum(total_non_imper_area_m2),
                                    total_cty_grp_area_m2 = sum(total_soaa_area_m2))
```


These table have been exported to the internal repository and will be used in the Results section to create an overall summary table comparing all URGR indicators.








<!--# 

Use this header for documenting the analyses. Put code in separate code chunks, and annotate the code in between using normal text (i.e. between the chunks, and try to avoid too many hashed out comments inside the code chunks). Add subheaders as needed. 

Code folding is activated, meaning the code will be hidden by default in the html (one can click to expand it).

Caching is also activated (from the top YAML), meaning that rendering to html will be quicker the second time you do it. This will create a folder inside you project folder (called INDICATORID_cache). Sometimes caching created problems because some operations are not rerun when they should be rerun. Try deleting the cash folder and try again.

-->

## 10. Results

### National results
```{r}
#| eval: true
#| code-summary: "Code to create a comparative URGR table"

# Load the results files
path_res <- "/data/P-Prosjekter2/412413_2023_no_egd/Results/URGR/"
urgr13 <- read_excel(paste0(path_res, "URGR_013_detailed_results_24MAY25.xlsx"))
urgr22 <- read_excel(paste0(path_res, "URGR_022_detailed_results_24MAY25.xlsx"))
urgr23 <- read.table(paste0(path_res, "URGR_023_detailed_results_27MAY2025.csv"))
urgr25 <- read.table(paste0(path_res, "URGR_025_detailed_results_26MAY2025.csv"))
urgr30 <- read.table(paste0(path_res, "URGR_030_detailed_results_26JUNE2025.csv"))
urgr31 <- read_excel(paste0(path_res, "URGR_031_fylke_results_18JUNE_25.xlsx"))

# Calculate URGR indicators
urgr13_national <- sum(urgr13$total_area_et_m2) / sum(unique(urgr13$lau_area_m2)) *100
urgr22_national <- sum(urgr22$total_area_et_m2) / sum(unique(urgr22$urb_domn_total_area)) *100
urgr23_national <- sum(urgr23$total_area_et_m2) / sum(unique(urgr23$soaa_total_area_m2)) *100
urgr25_national <- sum(urgr25$total_non_imper_area_m2) / sum(urgr25$total_soaa_area_m2) *100
urgr30_national <- sum(urgr30$total_non_imper_area_m2) / sum(urgr30$total_soaa_area_m2) *100
urgr31_national <- sum(urgr31$total_non_imper_area_m2) / sum(urgr31$total_soaa_area_m2) *100

# Create the table of outputs
urgr_vec_national <- c(urgr13_national,
                       urgr22_national,
                       urgr23_national,
                       urgr25_national,
                       urgr30_national,
                       urgr31_national)

names_vec_national <- c("URGR 13",
                        "URGR 22",
                        "URGR 23",
                        "URGR 25",
                        "URGR 30",
                        "URGR 31")

res_national <- data.frame(rep("Share of urban green areas", 6),
                           names_vec_national, 
                           rep("Norway", 6), 
                           rep(2018, 6),
                           urgr_vec_national)

colnames(res_national) <- c("Indicator",
                            "ID",
                            "Accounting area",
                            "Accounting period",
                            "Variable value (%)")

kbl(res_national)

```

### Regional results
```{r}
#| eval: true
#| warning: false
#| code-summary: "Code to create a comparative URGR table"

# Load the results files
path_res <- "/data/P-Prosjekter2/412413_2023_no_egd/Results/URGR/"
urgr13 <- read_excel(paste0(path_res, "URGR_013_detailed_results_24MAY25.xlsx"))
urgr22 <- read_excel(paste0(path_res, "URGR_022_detailed_results_24MAY25.xlsx"))
urgr23 <- read.table(paste0(path_res, "URGR_023_detailed_results_27MAY2025.csv"))
urgr25 <- read.table(paste0(path_res, "URGR_025_detailed_results_26MAY2025.csv"))
urgr30 <- read.table(paste0(path_res, "URGR_030_detailed_results_26JUNE2025.csv"))
urgr31 <- read_excel(paste0(path_res, "URGR_031_fylke_results_18JUNE_25.xlsx"))

path_region <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/NO_Fylke/"
regions <- read_excel(paste0(path_region, "kommune_fylke_region_NO_2024.xlsx"))

# Calculate URGR indicators
# Note that LAUD dataset uses the kommune codes from 2023
regions$kommune_nr_2023 <- as.character(regions$kommune_nr_2023)
regions$kommune_nr_2023[regions$kommune_nr_2023 == 301] <- "0301"

urgr13_regional <- urgr13 %>%
                    left_join(., regions, join_by(LAU_ID == kommune_nr_2023)) %>%
                    group_by(region_name) %>%
                    summarise(urban_green_area_m2 = sum(total_area_et_m2),
                              total_urban_area_m2 = sum(unique(lau_area_m2))) %>%
                    mutate(indicator = rep("URGR 13", nrow(.)),
                           urgr_regional = urban_green_area_m2 / total_urban_area_m2 * 100) %>%
                    select(region_name, indicator, urgr_regional)
                   
urgr22_regional <- urgr22 %>%
                    left_join(., regions, join_by(LAU_ID == kommune_nr_2023)) %>%
                    group_by(region_name) %>%
                    summarise(urban_green_area_m2 = sum(total_area_et_m2),
                              total_urban_area_m2 = sum(unique(urb_domn_total_area))) %>%
                    mutate(indicator = rep("URGR 22", nrow(.)),
                           urgr_regional= urban_green_area_m2 / total_urban_area_m2 * 100) %>%
                    select(region_name, indicator, urgr_regional)

regions$kommune_nr_2023 <- as.numeric(regions$kommune_nr_2023) 
regions$kommune_nr_2023[regions$kommune_nr_2023 == 0301] <- 301
urgr23_regional <- urgr23 %>%
                    left_join(., regions, join_by(LAU_ID == kommune_nr_2023)) %>%
                    group_by(region_name) %>%
                    summarise(urban_green_area_m2 = sum(total_area_et_m2),
                              total_urban_area_m2 = sum(unique(soaa_total_area_m2))) %>%
                    mutate(indicator = rep("URGR 23", nrow(.)),
                           urgr_regional = urban_green_area_m2 / total_urban_area_m2 * 100) %>%
                    select(region_name, indicator, urgr_regional)  


urgr25_regional <- urgr25 %>%
                    left_join(., regions, join_by(LAU_ID == kommune_nr_2023)) %>%
                    group_by(region_name) %>%
                    summarise(urban_green_area_m2 = sum(total_non_imper_area_m2),
                              total_urban_area_m2 = sum(total_soaa_area_m2)) %>%
                    mutate(indicator = rep("URGR 25", nrow(.)),
                           urgr_regional = urban_green_area_m2 / total_urban_area_m2 * 100) %>%
                    select(region_name, indicator, urgr_regional)  

urgr30_regional <- urgr30 %>%
                    left_join(., regions, join_by(fylkesnumm == fylke_nr)) %>%
                    group_by(region_name) %>%
                    summarise(urban_green_area_m2 = sum(total_non_imper_area_m2),
                              total_urban_area_m2 = sum(total_soaa_area_m2)) %>%
                    mutate(indicator = rep("URGR 30", nrow(.)),
                           urgr_regional = urban_green_area_m2 / total_urban_area_m2 * 100) %>%
                    select(region_name, indicator, urgr_regional)  

urgr31_regional <- urgr31 %>%
                    left_join(., regions, join_by(fylkesnumm == fylke_nr)) %>%
                    group_by(region_name) %>%
                    summarise(urban_green_area_m2 = sum(total_non_imper_area_m2),
                              total_urban_area_m2 = sum(total_soaa_area_m2)) %>%
                    mutate(indicator = rep("URGR 31", nrow(.)),
                           urgr_regional = urban_green_area_m2 / total_urban_area_m2 * 100) %>%
                    select(region_name, indicator, urgr_regional) 

# Create the table of outputs
urgr_df_regional <- bind_rows(urgr13_regional,
                              urgr22_regional,
                              urgr23_regional,
                              urgr25_regional,
                              urgr30_regional,
                              urgr31_regional)

res_regional <- data.frame(rep("Share of urban green areas", nrow(urgr_df_regional)),
                           urgr_df_regional$indicator, 
                           urgr_df_regional$region_name,
                           rep(2018, nrow(urgr_df_regional)),
                           urgr_df_regional$urgr_regional)

colnames(res_regional) <- c("Indicator",
                            "ID",
                            "Accounting area",
                            "Accounting period",
                            "Variable value (%)")

kbl(res_regional)

```


<!--# 

Repeat the final results here. Typically this is a map or table of indicator values.

This is typically where people will harvest data from, so make sure to include all relevant output here, but don't clutter this section with too much output either.

-->

## 11. Export file
```{r export}
#| eval: false
#| code-summary: "Code to export the result tables above"

#CSV
write.table(res_national, "URGR_NO_national_2018.csv")
write.table(res_regional, "URGR_NO_regional_2018.csv")

#Excel
write_xlsx(res_national, "URGR_NO_national_2018.xlsx")
write_xlsx(res_regional, "URGR_NO_regional_2018.xlsx")

```
<!--# 

Optional: Display the code (don't execute it) or the workflow for exporting the indicator values to file. Ideally the indicator values are exported as a georeferenced shape or raster file with indicators values, reference values and errors. You can also chose to export the raw (un-normalised or unscaled variable) as a seperate product. You should not save large sptaial output data on GitHub. You can use eval=FALSE to avoid code from being executed (example below - delete if not relevant) 

-->